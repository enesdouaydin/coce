import os
import csv
import json
from pathlib import Path
from dotenv import load_dotenv
from openai import AsyncOpenAI
import pandas as pd
from fuzzywuzzy import process, fuzz # type: ignore
import random
from datetime import datetime
import asyncio
import re

# .env dosyasÄ±ndan ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# Global Debug Modu
DEBUG_MODE = False

# OpenRouter Asenkron Ä°stemcisi ve BaÅŸlÄ±klar
async_client = None
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_REFERRER_FALLBACK = "http://localhost:3000"
OPENROUTER_X_TITLE_FALLBACK = "Sifir Arac Asistani"

OPENROUTER_REFERRER = os.getenv("OPENROUTER_REFERRER", OPENROUTER_REFERRER_FALLBACK)
_raw_x_title = os.getenv("OPENROUTER_X_TITLE", OPENROUTER_X_TITLE_FALLBACK)

COMPANY_NAME = "SÄ±fÄ±r AraÃ§ Nokta Com"

def sanitize_header_value(value: str, fallback: str = "Default App Title") -> str:
    try:
        value.encode('ascii')
        return value
    except UnicodeEncodeError:
        replacements = {
            'Ä±': 'i', 'Ä°': 'I', 'ÄŸ': 'g', 'Äž': 'G',
            'Ã¼': 'u', 'Ãœ': 'U', 'ÅŸ': 's', 'Åž': 'S',
            'Ã¶': 'o', 'Ã–': 'O', 'Ã§': 'c', 'Ã‡': 'C'
        }
        sanitized_value = value
        for tr_char, en_char in replacements.items():
            sanitized_value = sanitized_value.replace(tr_char, en_char)
        final_value = sanitized_value.encode('ascii', 'ignore').decode('ascii')
        if not final_value.strip():
            if DEBUG_MODE: print(f"âš ï¸ Header deÄŸeri '{value}' tamamen silindi, fallback '{fallback}' kullanÄ±lÄ±yor.")
            return fallback
        if DEBUG_MODE and final_value != value:
                print(f"â„¹ï¸ Header deÄŸeri sanitize edildi: '{value}' -> '{final_value}'")
        return final_value

SANITIZED_OPENROUTER_X_TITLE = sanitize_header_value(_raw_x_title, fallback="Generic App Title Header")

if OPENROUTER_API_KEY:
    async_client = AsyncOpenAI(
        base_url=os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1"),
        api_key=OPENROUTER_API_KEY,
    )
else:
    print("HATA: OPENROUTER_API_KEY .env dosyasÄ±nda bulunamadÄ± veya yÃ¼klenemedi.")

data_vehicles = [
    ['renault clio', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['clio', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['toyota yaris', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['volkswagen polo', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['hyundai i20', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['hyundai i10', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['seat ibiza', 'opel corsa', 'opel corsa elektrikli', 'peugeot 208', 'citroen c3', 'peugeot 308'],
    ['nissan x-trail', 'peugeot 5008', 'opel grandland', 'citroen c5 aircross', 'nissan xtrail', 'renault rafale'],
    ['toyota rav4', 'peugeot 5008', 'opel grandland', 'citroen c5 aircross', 'nissan xtrail', 'renault rafale'],
    ['toyota corolla cross', 'peugeot 5008', 'opel grandland', 'citroen c5 aircross', 'nissan xtrail', 'renault rafale'],
    ['hyundai bayon', 'opel crossland', 'citroen c4', 'citroen c4x', 'nissan juke', 'mokka'],
    ['fiat egea cross', 'opel crossland', 'citroen c4', 'citroen c4x', 'nissan juke', 'mokka'],
    ['skoda kamiq', 'opel crossland', 'citroen c4', 'citroen c4x', 'nissan juke', 'mokka'],
    ['seat ateca', 'opel crossland', 'citroen c4', 'citroen c4x', 'nissan qashqai', 'mokka'],
    ['ford focus hb', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['toyota corolla hb', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['toyota corollaa', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['renault megane sedan', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['hyundai elentra', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['skoda octavia', 'opel astra hb', 'opel astra elektrikli', 'peugeot 308', 'peugeot 308 elektrikli', None],
    ['skoda kodiaq', 'opel grandland', 'peugeot 3008', 'peugeot elektrikli 2008', 'nissan xtrail', None],
    ['kia sportage', 'opel grandland', 'peugeot 3008', 'peugeot elektrikli 2008', 'nissan qashqai', None],
    ['hyundai tucson', 'opel grandland', 'peugeot 3008', 'peugeot elektrikli 2008', 'nissan xtrail', None],
    ['volkswagen tiguan', 'opel grandland', 'peugeot 3008', 'peugeot elektrikli 2008', 'nissan xtrail', None],
    ['volkswagen t-roc', 'opel mokka', 'mokka elektrikli', 'peugeot 408', 'citroen c4x', 'nissan juke'],
    ['volkswagen t-cross', 'opel mokka', 'mokka elektrikli', 'peugeot 408', 'citroen c4x', 'nissan juke'],
    ['hyundai kona', 'opel mokka', 'mokka elektrikli', 'peugeot 408', 'citroen c4x', 'nissan qashqai'],
    ['ford kuga', 'opel grandland', 'peugeot 3008', 'peugeot elektrikli 2008', 'nissan qashqai', None],
    ['ford puma', 'opel mokka', 'mokka elektrikli', 'peugeot 408', 'citroen c4x', 'nissan juke'],
    ['skoda karoq', 'opel mokka', 'mokka elektrikli', 'peugeot 408', 'citroen c4x', 'nissan qashqai'],
    ['fiat doblo combi', 'opel combo life', 'none', None, None, None],
    ['fiat fiorino combi', 'opel combo life', 'none', None, None, None],
    ['ford tourneo connect', 'citroen berlingo', 'peugeot rifter', 'peugeot partner', 'opel combo cargo', 'opel combo life'],
    ['renault megane e tech', 'peugeot elektrikli 308', 'peugeot elektrikli 2008', 'opel mokka elektrikli', 'citroen elektrikli c4', 'citroen elektrikli c4x'],
    ['jeep avenger', 'peugeot elektrikli 308', 'peugeot elektrikli 2008', 'opel mokka elektrikli', 'citroen elektrikli c4', 'citroen elektrikli c4x'],
    ['toyota chr', 'peugeot elektrikli 308', 'peugeot elektrikli 2008', 'opel mokka elektrikli', 'citroen elektrikli c4', 'citroen elektrikli c4x']
]
columns_vehicles = ['Ã§eviri modelleri', 'eÅŸ deÄŸeri', 'elektrikli', 'Ã¶neri3', 'Ã¶neri4', 'Ã¶neri5']
df_vehicles = pd.DataFrame(data_vehicles, columns=columns_vehicles)

for col in columns_vehicles:
    df_vehicles[col] = df_vehicles[col].astype(str).str.lower().str.strip()
    df_vehicles[col].replace('none', None, inplace=True)
df_vehicles.replace('opel  corsa elektrikli', 'opel corsa elektrikli', inplace=True)
df_vehicles.replace('toyota corollaa', 'toyota corolla', inplace=True)

kullanicilar = [
    {"id": "0", "isim": "Ã–mer", "soyisim": "Can", "unvan": "Bey", "telefon": "5466630941", "marka": "Renault", "model": "Clio", "sehir": "Ä°stanbul", "ilce": "KadÄ±kÃ¶y"},
    {"id": "1", "isim": "AyÅŸe", "soyisim": "YÄ±lmaz", "unvan": "HanÄ±m", "telefon": "5301122233", "marka": "BMW", "model": "320i", "sehir": "Ä°stanbul", "ilce": "BeÅŸiktaÅŸ"},
    {"id": "2", "isim": "Mala", "soyisim": "Yarar", "unvan": "HanÄ±m", "telefon": "5395029860", "marka": "Toyota", "model": "Rav4", "sehir": "Ä°stanbul", "ilce": "Uskudar"},
    {"id": "3", "isim": "Asker", "soyisim": "YÄ±lmaz", "unvan": "Bey", "telefon": "5302342234", "marka": "Peugeot", "model": "5008", "sehir": "Ankara", "ilce": "Eryaman"}
]

session_rejected_models = []
fuzzy_matching_model_library_list = []
MODEL_LIBRARY_CSV_PATH = r"C:\Users\dou\Desktop\21.04.o\09\yeni\datala.csv"

FEMALE_NAMES_LIST = [ "ayÅŸe", "fatma", "zeynep", "selin", "elif", "merve", "derya", "ebru", "gamze", "aslÄ±", "burcu", "deniz", "ece", "ipek", "Ã¶zge", "gizem", "tuÄŸÃ§e", "damla", "pÄ±nar", "gÃ¼l", "canan", "filiz", "ÅŸeyma", "hande", "latife", "belgin", "ceren", "didem", "esra", "feride", "gÃ¶nÃ¼l", "hale", "jale", "kezban", "leyla", "mine", "nilgÃ¼n", "oya", "pelin", "rÃ¼ya", "sema", "tÃ¼lay", "Ã¼mmÃ¼han", "vildan", "yasemin", "zerrin", "Ã§iÄŸdem", "meltem", "serpil", "Ä±ÅŸÄ±l", "ilayda", "irem", "beste", "buse", "berra", "begÃ¼m", "mala"
]

def get_unvan(isim_str):
    if not isim_str or not isinstance(isim_str, str): return "Bey/HanÄ±m"
    return "HanÄ±m" if isim_str.lower() in FEMALE_NAMES_LIST else "Bey"

def load_external_model_library_from_csv(csv_file_path=MODEL_LIBRARY_CSV_PATH):
    global fuzzy_matching_model_library_list
    try:
        try: df_library = pd.read_csv(csv_file_path, encoding='utf-8')
        except UnicodeDecodeError: df_library = pd.read_csv(csv_file_path, encoding='iso-8859-9')
        all_models_set = set()
        for col in df_library.columns:
            valid_strings = df_library[col].dropna().astype(str).str.lower().str.strip()
            unique_models_in_col = valid_strings[valid_strings != ''].unique()
            all_models_set.update(unique_models_in_col)
        if 'none' in all_models_set: all_models_set.remove('none')
        if 'araÃ§' in all_models_set: all_models_set.remove('araÃ§')
        fuzzy_matching_model_library_list = list(all_models_set)
        if not fuzzy_matching_model_library_list:
            print(f"UYARI: '{csv_file_path}' dosyasÄ±ndan harici model kÃ¼tÃ¼phanesi okunamadÄ± veya boÅŸ.")
            return False
        if DEBUG_MODE: print(f"Harici model kÃ¼tÃ¼phanesi {len(fuzzy_matching_model_library_list)} modelle CSV'den yÃ¼klendi.")
        return True
    except FileNotFoundError:
        print(f"HATA: CSV dosyasÄ± ('{csv_file_path}') bulunamadÄ±."); fuzzy_matching_model_library_list = []; return False
    except pd.errors.EmptyDataError:
        print(f"HATA: CSV dosyasÄ± ('{csv_file_path}') boÅŸ."); fuzzy_matching_model_library_list = []; return False
    except Exception as e:
        print(f"HATA: CSV dosyasÄ± ('{csv_file_path}') okunurken hata: {e}"); fuzzy_matching_model_library_list = []; return False

def find_models_in_text_from_library(user_text, model_library):
    if not user_text or not model_library: return []
    user_text_lower = user_text.lower()
    found_models = set()
    sorted_library = sorted(model_library, key=len, reverse=True)
    for lib_model in sorted_library:
        pattern = r"\b" + re.escape(lib_model) + r"\b"
        if re.search(pattern, user_text_lower):
            is_substring = any(lib_model in fm for fm in found_models if len(fm) > len(lib_model))
            if not is_substring:
                found_models = {fm for fm in found_models if fm not in lib_model or len(fm) >= len(lib_model)}
                found_models.add(lib_model)
    final_found_models = list(found_models)
    if DEBUG_MODE: print(f"ðŸ•µï¸â€â™‚ï¸ KÃ¼tÃ¼phaneden Model Tespiti (find_models_in_text_from_library): '{user_text}' -> {final_found_models}")
    return final_found_models

def suggest_vehicle_alternative(requested_vehicle, vehicle_df):
    global session_rejected_models, DEBUG_MODE
    aranan_arac_original_case = requested_vehicle
    aranan_arac = str(requested_vehicle).lower().strip()
    direct_availability_columns = ['eÅŸ deÄŸeri', 'elektrikli', 'Ã¶neri3', 'Ã¶neri4', 'Ã¶neri5']

    if aranan_arac in session_rejected_models and DEBUG_MODE:
        print(f"â„¹ï¸ '{aranan_arac_original_case}' daha Ã¶nce reddedilmiÅŸti, alternatif aranÄ±yor (suggest_vehicle_alternative).")

    for idx, row in vehicle_df.iterrows():
        ceviri_modeli_excel = row.get('Ã§eviri modelleri')
        if ceviri_modeli_excel and aranan_arac == ceviri_modeli_excel:
            es_degeri_excel = row.get('eÅŸ deÄŸeri')
            if es_degeri_excel and es_degeri_excel not in session_rejected_models:
                return {
                    "durum": 1, "bulunan": ceviri_modeli_excel, "Ã¶neri": es_degeri_excel, "excelde_var": True,
                    "mesaj": f"AradÄ±ÄŸÄ±nÄ±z '{str(aranan_arac_original_case).capitalize()}' modeline ({str(ceviri_modeli_excel).capitalize()} olarak kayÄ±tlÄ±) alternatif olarak '{str(es_degeri_excel).capitalize()}' modelini Ã¶nerebiliriz."}
            elif es_degeri_excel and es_degeri_excel in session_rejected_models and DEBUG_MODE:
                 print(f"â„¹ï¸ '{str(ceviri_modeli_excel).capitalize()}' iÃ§in eÅŸdeÄŸer '{str(es_degeri_excel).capitalize()}' reddedilmiÅŸ.")
            break
    for sutun_adi in direct_availability_columns:
        matching_rows = vehicle_df[vehicle_df[sutun_adi] == aranan_arac]
        if not matching_rows.empty:
            model_in_sutun = matching_rows.iloc[0][sutun_adi]
            if model_in_sutun not in session_rejected_models:
                return {"durum": 2, "bulunan": model_in_sutun, "Ã¶neri": model_in_sutun, "excelde_var": True, "mesaj": f"Evet, '{str(model_in_sutun).capitalize()}' modelimiz mevcut. Size bu aracÄ± sunabiliriz."}
            elif DEBUG_MODE:
                print(f"â„¹ï¸ Bulunan '{str(model_in_sutun).capitalize()}' modeli ('{sutun_adi}' sÃ¼tununda) reddedilenler listesinde.")

    random_pool_columns = ['eÅŸ deÄŸeri', 'elektrikli', 'Ã¶neri3', 'Ã¶neri4', 'Ã¶neri5']
    potential_random_suggestions_map = {}
    for sutun in random_pool_columns:
        valid_models_in_col = vehicle_df[sutun].dropna().unique()
        for model_aday_lower in valid_models_in_col:
            if model_aday_lower != aranan_arac and model_aday_lower not in session_rejected_models and model_aday_lower is not None:
                if model_aday_lower not in potential_random_suggestions_map:
                     potential_random_suggestions_map[model_aday_lower] = model_aday_lower
    potential_random_suggestions_list = list(potential_random_suggestions_map.values())
    if potential_random_suggestions_list:
        rastgele_oneri = random.choice(potential_random_suggestions_list)
        return {"durum": 3, "bulunan": aranan_arac_original_case, "Ã¶neri": rastgele_oneri, "excelde_var": False, "mesaj": f"AradÄ±ÄŸÄ±nÄ±z '{str(aranan_arac_original_case).capitalize()}' modelini ÅŸu anda doÄŸrudan portfÃ¶yÃ¼mÃ¼zde bulamadÄ±k. Ancak size alternatif olarak '{str(rastgele_oneri).capitalize()}' modelini Ã¶nerebiliriz."}
    return {"durum": 4, "bulunan": aranan_arac_original_case, "Ã¶neri": None, "excelde_var": False, "mesaj": f"Maalesef '{str(aranan_arac_original_case).capitalize()}' modeli iÃ§in portfÃ¶yÃ¼mÃ¼zde size ÅŸu anda uygun bir alternatif bulamÄ±yoruz."}

def parse_agent_response_json(response_str: str, agent_name: str = "Agent"):
    if DEBUG_MODE: print(f"ðŸ“„ {agent_name} Ham YanÄ±t: {response_str}")
    try:
        data = json.loads(response_str)
        return data
    except json.JSONDecodeError:
        if DEBUG_MODE: print(f"âš ï¸ {agent_name}: Ham yanÄ±t doÄŸrudan JSON deÄŸil, metin iÃ§i JSON aranÄ±yor.")
        match_obj = re.search(r'```json\s*(\{[\s\S]*?\}|\[[\s\S]*?\])\s*```|(\{[\s\S]*?\}|\[[\s\S]*?\])', response_str, re.DOTALL)
        if match_obj:
            json_part = None
            if match_obj.group(1): json_part = match_obj.group(1)
            elif match_obj.group(2): json_part = match_obj.group(2)
            elif match_obj.group(0) and not (match_obj.group(0).startswith("```") and not match_obj.group(0).endswith("```")): json_part = match_obj.group(0)
            if json_part:
                try:
                    data = json.loads(json_part)
                    if DEBUG_MODE: print(f"â„¹ï¸ {agent_name}: Metin iÃ§inden JSON baÅŸarÄ±yla ayÄ±klandÄ±.")
                    return data
                except json.JSONDecodeError as e_inner:
                    if DEBUG_MODE: print(f"âŒ {agent_name}: AyÄ±klanan bÃ¶lÃ¼m JSON parse edilemedi: '{json_part}'. Hata: {e_inner}")
            elif DEBUG_MODE: print(f"âŒ {agent_name}: JSON regex eÅŸleÅŸti ama JSON bÃ¶lÃ¼mÃ¼ boÅŸ geldi.")
        if DEBUG_MODE: print(f"âŒ {agent_name}: YanÄ±tta geÃ§erli JSON bloÄŸu bulunamadÄ±.")
        return {"error": f"{agent_name}: YanÄ±tta JSON bulunamadÄ± veya parse edilemedi", "raw_response": response_str}

async def safe_openrouter_request_async(system_prompt_str, user_prompt_str,
                                        model_name="meta-llama/llama-guard-4-12b",
                                        temperature=0.1, max_tokens=500, expect_json=False):
    global async_client
    if async_client is None: return "API_ERROR: Asenkron istemci baÅŸlatÄ±lamadÄ±."
    messages = [{"role": "system", "content": system_prompt_str}, {"role": "user", "content": user_prompt_str}]
    request_params = {"model": model_name, "messages": messages, "temperature": temperature, "max_tokens": max_tokens,
                      "extra_headers": {"HTTP-Referer": OPENROUTER_REFERRER, "X-Title": SANITIZED_OPENROUTER_X_TITLE}}
    if expect_json: request_params["response_format"] = {"type": "json_object"}
    if DEBUG_MODE: print(f"\n--- OpenRouter Asenkron Ä°steÄŸi ({model_name}) ---")
    try:
        completion = await async_client.chat.completions.create(**request_params)
        response_content = completion.choices[0].message.content
        if DEBUG_MODE: print(f"âœ… OpenRouter YanÄ±t AlÄ±ndÄ± ({model_name}).")
        return response_content
    except Exception as e:
        print(f"âŒ OpenRouter API HatasÄ± ({model_name}): {e}"); return f"API_ERROR: Model yanÄ±t veremedi ({str(e)})"

def format_structured_history(gecmis_mesajlar_list_param, turns=5):
    if not gecmis_mesajlar_list_param: return "KonuÅŸma geÃ§miÅŸi henÃ¼z bulunmamaktadÄ±r."
    history_to_format = gecmis_mesajlar_list_param[-(turns*2):]
    history_str_parts = []
    for msg_obj in history_to_format:
        prefix = "User: " if msg_obj["role"] == "user" else "AI: "
        history_str_parts.append(f"{prefix}{msg_obj['content']}")
    return "\n".join(history_str_parts)

LLM_DRIVEN_PROMPTS = {
    "INTENT_ENTITY_EXTRACTOR": """SENARYO: Sen bir metin analiz uzmanÄ±sÄ±n. GÃ¶revin, kullanÄ±cÄ±nÄ±n SON MESAJINDAN ve kÄ±sa konuÅŸma geÃ§miÅŸinden ana niyetini ve ilgili varlÄ±klarÄ± JSON formatÄ±nda Ã§Ä±karmak.

KULLANILABÄ°LÄ°R NÄ°YETLER (Sadece bu listeden birini kullan, EN UYGUN OLANI SEÃ‡):
- KIMLIK_ONAYLAMA: KullanÄ±cÄ± kimliÄŸini doÄŸruluyor ("evet", "benim", "doÄŸru" gibi).
- KIMLIK_DUZELTME_ISIM_VERME: KullanÄ±cÄ± kendi ismini veriyor/dÃ¼zeltiyor ("hayÄ±r ben X Y", "adÄ±m Z").
- KIMLIK_REDDETME_GENEL: KullanÄ±cÄ± sorulan kiÅŸi olmadÄ±ÄŸÄ±nÄ± genel bir ifadeyle belirtiyor ("hayÄ±r deÄŸilim", "yanlÄ±ÅŸ numara").
- NEREDEN_ARADINIZ_SORUSU: KullanÄ±cÄ± nereden/kimin aradÄ±ÄŸÄ±nÄ± soruyor ("kimsin", "nereden arÄ±yorsun").
- ARAC_SORGU_YENI: KullanÄ±cÄ± yeni bir veya daha fazla araÃ§ modeli/tipi soruyor, ilgilendiÄŸini belirtiyor (Ã¶rn: "dizel ne var", "corsa var mÄ±").
- ARAC_SORGU_DETAY_FIYAT: KullanÄ±cÄ± bir model hakkÄ±nda teknik detay, fiyat, kampanya vb. soruyor (Ã¶rn: "corsanÄ±n Ã¶zellikleri neler", "fiyatÄ± ne kadar").
- TEKLIFI_ONAYLAMA: KullanÄ±cÄ± daha Ã¶nce AI tarafÄ±ndan yapÄ±lan bir araÃ§ Ã¶nerisini, bayi iletiÅŸimi teklifini veya bir sonraki adÄ±mÄ± onaylÄ±yor (Ã¶rn: "evet", "tamam", "olur", "kabul ediyorum", "hee", "he", "elbette", "tabii ki", "hÄ± hÄ±"). Onay durumu 'true' olmalÄ±.
- TEKLIFI_REDDETME_ALTERNATIF_ISTEME: KullanÄ±cÄ± bir Ã¶nceki Ã¶neriyi reddedip alternatif soruyor veya farklÄ± bir model belirtiyor (Ã¶rn: "hayÄ±r onu istemiyorum, bana ÅŸunu gÃ¶ster").
- TEKLIFI_REDDETME_KAPATMA: KullanÄ±cÄ± bir Ã¶nceki Ã¶neriyi reddedip gÃ¶rÃ¼ÅŸmeyi sonlandÄ±rmak istiyor.
- VEDALASMA_KAPATMA: KullanÄ±cÄ± teÅŸekkÃ¼r edip gÃ¶rÃ¼ÅŸmeyi sonlandÄ±rÄ±yor.
- ANLAMADIM_TEKRAR_ISTEGI: KullanÄ±cÄ± bir Ã¶nceki mesajÄ± anlamadÄ±ÄŸÄ±nÄ± belirtip tekrar istiyor.
- KULLANICI_TUTARSIZLIK_ALGILADI: KullanÄ±cÄ±, AI'Ä±n Ã¶nceki ifadeleriyle Ã§eliÅŸtiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼ bir durumu belirtiyor (Ã¶rn: "az Ã¶nce yok dedin ÅŸimdi var diyorsun", "Ã¶nce Ã¶yle dememiÅŸtin").
- GENEL_ONERI_ISTEGI: KullanÄ±cÄ± genel araÃ§ Ã¶nerisi istiyor ("baÅŸka ne var?", "ne Ã¶nerirsin?", "model tavsiyen var mÄ±?").
- CALISTIGINIZ_MARKALARI_SORMA: KullanÄ±cÄ± ÅŸirketin Ã§alÄ±ÅŸtÄ±ÄŸÄ±/elinde bulunan araÃ§ markalarÄ±nÄ± genel olarak soruyor ("hangi markalar var?", "sadece opel mi satÄ±yorsunuz?").
- BELIRSIZ_ALAKASIZ: YukarÄ±daki niyetlerden hiÃ§biri deÄŸil veya konu dÄ±ÅŸÄ±. KÄ±sa, tek kelimelik tepkiler ("hmm", "anladÄ±m" gibi) eÄŸer bir teklife doÄŸrudan yanÄ±t deÄŸilse bu kategoriye girebilir.

Ã‡IKARILACAK VARLIKLAR (Ä°lgili olanlarÄ± doldur, olmayanlarÄ± null veya boÅŸ liste [] olarak bÄ±rak. AraÃ§ model/marka/tiplerini KÃœÃ‡ÃœK HARFE Ã§evir):
- "modeller": KullanÄ±cÄ±nÄ±n SON MESAJINDA sorduÄŸu veya bahsettiÄŸi araÃ§ modellerinin listesi.
- "markalar": KullanÄ±cÄ±nÄ±n SON MESAJINDA sorduÄŸu araÃ§ markalarÄ±nÄ±n listesi.
- "tipler": KullanÄ±cÄ±nÄ±n SON MESAJINDA sorduÄŸu araÃ§ tiplerinin listesi (Ã¶rn: "elektrikli", "dizel", "suv").
- "isim_soyisim": KullanÄ±cÄ± kimlik dÃ¼zeltirken verdiÄŸi tam isim (Ã¶rn: "Ahmet YÄ±lmaz").
- "onay_durumu": KullanÄ±cÄ± bir teklifi TEKLIFI_ONAYLAMA niyetiyle yanÄ±tlÄ±yorsa true, TEKLIFI_REDDETME_... niyetlerinden biriyle yanÄ±tlÄ±yorsa false. DiÄŸer sorgu veya genel ifadelerde null. Ã–NEMLÄ°: KullanÄ±cÄ± yeni bir soru soruyorsa (Ã¶rn: ARAC_SORGU_YENI), bu bir Ã¶nceki teklife onay/red anlamÄ±na gelmez, bu durumda onay_durumu null olmalÄ±dÄ±r.

BÄ°LÄ°NEN BAZI ARAÃ‡ MODELLERÄ° (DoÄŸru tanÄ±ma iÃ§in yardÄ±mcÄ± olabilir, sadece bunlarla sÄ±nÄ±rlÄ± kalma):
{BILINEN_MODEL_LISTESI_KISMI}

KÄ±sa KonuÅŸma GeÃ§miÅŸi (Son birkaÃ§ mesaj):
{KONUSMA_GECMISI_KISA}

KullanÄ±cÄ±nÄ±n Son MesajÄ±:
{KULLANICI_MESAJI}

LÃ¼tfen Ã§Ä±ktÄ±nÄ± SADECE AÅžAÄžIDAKÄ° JSON FORMATINDA VER. BaÅŸka hiÃ§bir aÃ§Ä±klama veya metin ekleme.
{{
  "intent": "NIYET_ETIKETI_BURAYA",
  "entities": {{
    "modeller": [], "markalar": [], "tipler": [], "isim_soyisim": null, "onay_durumu": null
  }},
  "raw_utterance_processed": "{KULLANICI_MESAJI_TEKRAR}"
}}
""",
    "IDENTITY_HANDLER_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan bir kimlik yÃ¶netimi ve mÃ¼ÅŸteri karÅŸÄ±lama uzmanÄ±sÄ±n. Ana gÃ¶revin, aranan kiÅŸinin doÄŸru kiÅŸi olup olmadÄ±ÄŸÄ±nÄ± teyit etmek, yanlÄ±ÅŸ kiÅŸiyse yeni kiÅŸinin kim olduÄŸunu Ã¶ÄŸrenip onlara genel bir bilgi teklifinde bulunmak, veya doÄŸru kiÅŸiyse ve daha Ã¶nceden bir profil aracÄ± varsa onunla ilgili bilgi sunmaktÄ±r.

SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- Hedeflenen Orijinal Profil: {ORIJINAL_PROFIL_BILGISI}
- Profil AracÄ± Analizi (KullanÄ±cÄ±ya sunulacak mesaj): {PROFIL_ARACI_ANALIZI}
- Ã–nceki AI Sorusu Tipi: {ONCEKI_AI_SORU_TIPI}
- KullanÄ±cÄ±nÄ±n Son Niyeti (Intent Agent'tan): {DETECTED_INTENT}
- KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{KULLANICI_MESAJI}"

GÃ–REVLERÄ°N:
KullanÄ±cÄ±nÄ±n niyeti (`DETECTED_INTENT`) ve Ã¶nceki AI soru tipine (`ONCEKI_AI_SORU_TIPI`) gÃ¶re aÅŸaÄŸÄ±daki JSON Ã§Ä±ktÄ±larÄ±ndan uygun olanÄ± Ã¼ret.

1.  EÄžER `DETECTED_INTENT` == "KIMLIK_REDDETME_GENEL":
    ```json
    {{
      "agent_karari": "KIMLIK_REDDI_YENIDEN_SOR",
      "guncellenmis_isim_soyisim": null,
      "kullanici_yaniti_metni": "AnladÄ±m. Peki, bu durumda kiminle gÃ¶rÃ¼ÅŸtÃ¼ÄŸÃ¼mÃ¼ Ã¶ÄŸrenebilir miyim acaba?",
      "sonraki_python_durumu_onerisi": "KIMLIK_DOGRULAMA_BASLANGIC",
      "ai_sordu_soru_tipi": "KIMLIK_ISIM_SORUSU"
    }}
    ```
2.  EÄžER `DETECTED_INTENT` == "KIMLIK_DUZELTME_ISIM_VERME" VE `ONCEKI_AI_SORU_TIPI` == "KIMLIK_ISIM_SORUSU":
    ```json
    {{
      "agent_karari": "YENI_KISI_TANIMLANDI",
      "guncellenmis_isim_soyisim": "[KullanÄ±cÄ±nÄ±n verdiÄŸi yeni tam isim]",
      "kullanici_yaniti_metni": "[Tespit edilen yeni isim], ben {COMPANY_NAME}'dan arÄ±yorum. Size nasÄ±l yardÄ±mcÄ± olabilirim?",
      "sonraki_python_durumu_onerisi": "ARAC_ISLEME",
      "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU"
    }}
    ```
3.  EÄžER `DETECTED_INTENT` == "KIMLIK_ONAYLAMA":
    (NOT: {PROFIL_ARACI_ANALIZI} Python'dan kullanÄ±cÄ± dostu bir metin olarak gelmeli. EÄŸer boÅŸsa, genel yardÄ±m sorusu sor.)
    ```json
    {{
      "agent_karari": "ONAYLANDI",
      "guncellenmis_isim_soyisim": null,
      "kullanici_yaniti_metni": "TeÅŸekkÃ¼rler {ORIGINAL_PROFILE_ISIM}. [EÄžER {PROFIL_ARACI_ANALIZI} doluysa: {PROFIL_ARACI_ANALIZI} Bu Ã¶neriyle ilgilenir misiniz? EÄžER {PROFIL_ARACI_ANALIZI} boÅŸsa: Size nasÄ±l yardÄ±mcÄ± olabilirim?]",
      "sonraki_python_durumu_onerisi": "ARAC_ISLEME",
      "ai_sordu_soru_tipi": "[Duruma gÃ¶re ARAC_ILGI_SORUSU veya GENEL_YARDIM_SORUSU]"
    }}
    ```
4.  EÄžER `DETECTED_INTENT` == "KIMLIK_DUZELTME_ISIM_VERME" VE `ONCEKI_AI_SORU_TIPI` != "KIMLIK_ISIM_SORUSU":
    ```json
    {{
      "agent_karari": "DUZELTILDI_FARKLI_KISI",
      "guncellenmis_isim_soyisim": "[KullanÄ±cÄ±nÄ±n verdiÄŸi yeni tam isim]",
      "kullanici_yaniti_metni": "AnladÄ±m, teÅŸekkÃ¼rler [Tespit edilen yeni isim]. Ben {COMPANY_NAME}'dan Arda. Size nasÄ±l yardÄ±mcÄ± olabilirim?",
      "sonraki_python_durumu_onerisi": "ARAC_ISLEME",
      "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU"
    }}
    ```
""",
    "VEHICLE_INQUIRY_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan bir araÃ§ bilgi uzmanÄ±sÄ±n. GÃ¶revin, kullanÄ±cÄ±nÄ±n belirli araÃ§ modelleri veya tipleri hakkÄ±ndaki sorularÄ±na yanÄ±t vermek.

SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- MÃ¼ÅŸteri AdÄ± SoyadÄ± (Teyitli): {MUSTERI_ADI_SOYADI_UNVAN}
- Python AraÃ§ Analiz SonuÃ§larÄ± (KullanÄ±cÄ±nÄ±n sorduÄŸu her model/tip iÃ§in): {PYTHON_ARAC_ANALIZ_SONUCLARI}
- Reddedilen Modeller Listesi: {REDDEDILEN_MODELLER}
- KullanÄ±cÄ±nÄ±n Ä°lgilendiÄŸi Modeller/Tipler: {KULLANICININ_SORDUGU_MODELLER_VE_TIPLER}
- KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{KULLANICI_MESAJI}"

GÃ–REVLERÄ°N:
1. EÄŸer kullanÄ±cÄ± belirli modeller sorduysa ({KULLANICININ_SORDUGU_MODELLER_VE_TIPLER} iÃ§inde model varsa):
   a. Her model iÃ§in {PYTHON_ARAC_ANALIZ_SONUCLARI}'nÄ± incele.
   b. MEVCUT (Durum 2) ise: "Evet, [Model AdÄ±] mevcut."
   c. EÅžDEÄžERÄ° VAR (Durum 1) ise: "[SorduÄŸu Model] iÃ§in [EÅŸdeÄŸer Model] Ã¶nerebiliriz."
   d. ALTERNATÄ°F VAR (Durum 3) ise: "[SorduÄŸu Model] yok ama [Alternatif Model] Ã¶nerebiliriz."
   e. BULUNAMADI (Durum 4) ise: "Maalesef [SorduÄŸu Model] iÃ§in bir seÃ§eneÄŸimiz yok."
   f. Birden fazla model varsa, yanÄ±tlarÄ± birleÅŸtir. Sonunda "Bu model(ler)le ilgilenir misiniz?" diye sor.
2. EÄŸer kullanÄ±cÄ± belirli bir ARAÃ‡ TÄ°PÄ° sorduysa (Ã¶rn: "elektrikli araÃ§", "dizel suv", {KULLANICININ_SORDUGU_MODELLER_VE_TIPLER} iÃ§inde tip varsa):
   a. {PYTHON_ARAC_ANALIZ_SONUCLARI} iÃ§inde bu tipe uygun genel bir Ã¶neri metni varsa onu kullan.
   b. EÄŸer Python Ã¶zel bir analiz sunmadÄ±ysa, genel olarak "Evet, {KULLANICININ_SORDUGU_MODELLER_VE_TIPLER} araÃ§larÄ±mÄ±z mevcut. Ã–rneÄŸin portfÃ¶yÃ¼mÃ¼zdeki [Model A], [Model B] gibi seÃ§eneklerimiz var. Bu tÃ¼r araÃ§larla mÄ± ilgileniyorsunuz?" gibi bir yanÄ±t ver. (Model A, B yi portfÃ¶yden, reddedilmeyenlerden rastgele seÃ§)
3. PortfÃ¶y dÄ±ÅŸÄ± bir model iÃ§in Ä±srar edilirse, o markayla Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ±zÄ± belirt.
4. YanÄ±tÄ±n kÄ±sa ve doÄŸal olmalÄ±. Reddedilen modelleri ASLA Ã¶nerme.

JSON Ã‡IKTI FORMATI:
{{
  "kullanici_yaniti_metni": "[MÃ¼ÅŸteriye verilecek tam yanÄ±t metni]",
  "onerilen_veya_teyit_edilen_modeller_yanitta": ["[YanÄ±tÄ±nda MEVCUT OLDUÄžUNU TEYÄ°T ETTÄ°ÄžÄ°N veya AKTÄ°F BÄ°R ALTERNATÄ°F OLARAK SUNDUÄžUN modellerin listesi (kÃ¼Ã§Ã¼k harf)]"],
  "unavailable_models_queried": ["[EÄŸer model bulunamadÄ±ysa (Durum 4), bulunamayan orijinal modellerin listesi]"],
  "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR",
  "ai_sordu_soru_tipi": "ARAC_ILGI_SORUSU" 
}}
""", # Alternatif sunma onay sorusu da olabilir, agent karar vermeli.
    "GENERAL_RECOMMENDATION_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan bir araÃ§ Ã¶neri uzmanÄ±sÄ±n. MÃ¼ÅŸteri genel olarak "baÅŸka ne Ã¶nerirsin?" gibi bir talepte bulundu.

SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- MÃ¼ÅŸteri AdÄ± SoyadÄ± (Teyitli): {MUSTERI_ADI_SOYADI_UNVAN}
- Python TarafÄ±ndan HazÄ±rlanan Genel Ã–neri Listesi (EÄŸer varsa): {PYTHON_GENEL_ONERI_LISTESI}
- Daha Ã–nce KonuÅŸulan/Reddedilen Modeller: {KONUSULAN_REDDEDILEN_MODELLER}
- YakÄ±n Zamanda Sorulan ve Bulunamayan Modeller BaÄŸlamÄ±: {RECENTLY_UNAVAILABLE_MODELS_CONTEXT}

KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{KULLANICI_MESAJI}"

GÃ–REVLERÄ°N:
1.  EÄŸer Python bir Ã¶neri listesi verdiyse ({PYTHON_GENEL_ONERI_LISTESI}), o listeden 1-2 uygun model seÃ§erek Ã¶ner.
2.  EÄŸer {RECENTLY_UNAVAILABLE_MODELS_CONTEXT} bilgisi anlamlÄ±ysa ve Ã¶neri listenizde bu bilgiyle alakalÄ± bir model varsa, bu durumu aÃ§Ä±klayarak Ã¶nerin.
3.  Emin deÄŸilsen veya uygun model bulamazsan, mÃ¼ÅŸteriye hangi segmentte veya Ã¶zelliklerde araÃ§ aradÄ±ÄŸÄ±nÄ± sor.
4.  YanÄ±tÄ±n Ã‡OK KISA ve doÄŸal olmalÄ±.
JSON Ã‡IKTI FORMATI:
{{
  "kullanici_yaniti_metni": "[MÃ¼ÅŸteriye verilecek tam yanÄ±t metni]",
  "onerilen_modeller_yanitta": ["[YanÄ±tÄ±nda Ã¶nerdiÄŸin modellerin listesi (kÃ¼Ã§Ã¼k harf)]"],
  "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR",
  "ai_sordu_soru_tipi": "ARAC_ILGI_SORUSU"
}}
""",
"OFFER_RESPONSE_HANDLER_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan bir satÄ±ÅŸ destek uzmanÄ±sÄ±n. Bir Ã¶nceki turda mÃ¼ÅŸteriye bir teklifte bulunuldu (Ã¶rn: bayi aramasÄ±, belirli bir modelle ilgilenip ilgilenmediÄŸi soruldu) ve mÃ¼ÅŸteri bu teklife yanÄ±t verdi. Ã–NEMLÄ°: Bu agent SADECE kullanÄ±cÄ± AI'Ä±n bir Ã¶nceki sorusuna/teklifine DOÄžRUDAN yanÄ±t veriyorsa (onay, red, vs.) Ã§aÄŸrÄ±lmalÄ±dÄ±r. EÄŸer kullanÄ±cÄ± yeni bir araÃ§ sorgusu yapÄ±yorsa veya konuyla alakasÄ±z bir ÅŸey sÃ¶ylÃ¼yorsa, OrkestratÃ¶r bu durumu farklÄ± ele almalÄ± ve bu agent'Ä± Ã§aÄŸÄ±rmamalÄ±dÄ±r.

SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- MÃ¼ÅŸteri AdÄ± SoyadÄ± (Teyitli): {MUSTERI_ADI_SOYADI_UNVAN}
- Bir Ã–nceki AI Sorusu Tipi: {ONCEKI_AI_SORU_TIPI}
- Ã–nceki Turda KonuÅŸulan/Teklif Edilen Modeller: {ONCEKI_TUR_MODELLERI}
- Python TarafÄ±ndan SaÄŸlanan Alternatifler Metni (EÄŸer {ONCEKI_AI_SORU_TIPI} == "ALTERNATIF_SUNMA_ONAY_SORUSU" ise ve onaylandÄ±ysa): {PYTHON_PROVIDED_ALTERNATIVES_TEXT}

KullanÄ±cÄ±nÄ±n Son MesajÄ± (Teklife YanÄ±tÄ±): "{KULLANICI_MESAJI}"
Niyet Agent'Ä± Ã‡Ä±ktÄ±sÄ± (KullanÄ±cÄ±nÄ±n yanÄ±tÄ±nÄ±n niyeti): {NIYET_AGENT_CIKTISI}

GÃ–REVLERÄ°N (SÄ±rayla deÄŸerlendir):

1.  **KULLANICI TEKLÄ°FÄ° ONAYLADIYSA (`{NIYET_AGENT_CIKTISI}.entities.onay_durumu == true`):**
    a.  EÄžER `{ONCEKI_AI_SORU_TIPI}` == "ALTERNATIF_SUNMA_ONAY_SORUSU" VE `{PYTHON_PROVIDED_ALTERNATIVES_TEXT}` anlamlÄ±ysa:
        ```json
        {{ "kullanici_yaniti_metni": "{PYTHON_PROVIDED_ALTERNATIVES_TEXT} Bu modellerle ilgilenir misiniz?", "teklif_onay_durumu_python_icin": true, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR", "ai_sordu_soru_tipi": "ARAC_ILGI_SORUSU" }}
        ```
    b.  EÄžER `{ONCEKI_AI_SORU_TIPI}` == "BAYI_ONAY_SORUSU":
        ```json
        {{ "kullanici_yaniti_metni": "Harika! Yetkili bayimiz [{ONCEKI_TUR_MODELLERI} hakkÄ±nda] en kÄ±sa sÃ¼rede sizinle iletiÅŸime geÃ§ecektir. BaÅŸka bir konuda yardÄ±mcÄ± olabilir miyim?", "teklif_onay_durumu_python_icin": true, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "ARAC_ISLEME", "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU" }}
        ```
    c.  EÄžER `{ONCEKI_AI_SORU_TIPI}` == "ARAC_ILGI_SORUSU":
        ```json
        {{ "kullanici_yaniti_metni": "AnladÄ±m, [{ONCEKI_TUR_MODELLERI} listesindeki Ä°LK MODELÄ° yaz] ile ilgileniyorsunuz. Bu model iÃ§in sizi yetkili bayimizin aramasÄ±nÄ± organize etmemi ister misiniz?", "teklif_onay_durumu_python_icin": true, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR", "ai_sordu_soru_tipi": "BAYI_ONAY_SORUSU" }}
        ```
    d.  EÄžER `{ONCEKI_AI_SORU_TIPI}` == "BAYI_MODEL_TEYIT_SORUSU" VE `{NIYET_AGENT_CIKTISI}.entities.modeller` doluysa:
        ```json
        {{ "kullanici_yaniti_metni": "TamamdÄ±r, [{NIYET_AGENT_CIKTISI}.entities.modeller iÃ§indeki ilk model] iÃ§in bayi aramasÄ± organize ediyorum. En kÄ±sa sÃ¼rede sizinle iletiÅŸime geÃ§ecekler. BaÅŸka bir konuda yardÄ±mcÄ± olabilir miyim?", "teklif_onay_durumu_python_icin": true, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "ARAC_ISLEME", "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU" }}
        ```
    e.  DÄ°ÄžER ONAY DURUMLARI (Ã¶rn: `{ONCEKI_AI_SORU_TIPI}` == "BAYI_MODEL_TEYIT_SORUSU" ama kullanÄ±cÄ± model belirtmediyse veya genel bir onaysa):
        ```json
        {{ "kullanici_yaniti_metni": "AnladÄ±m, bir bayi yÃ¶nlendirmesi konusunda size yardÄ±mcÄ± olmamÄ± istiyorsunuz. Hangi belirli model veya modeller iÃ§in yetkili bayimizin sizinle iletiÅŸime geÃ§mesini istersiniz?", "teklif_onay_durumu_python_icin": true, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR", "ai_sordu_soru_tipi": "BAYI_MODEL_TEYIT_SORUSU" }}
        ```
2.  **KULLANICI TEKLÄ°FÄ° REDDETTÄ°YSE (`{NIYET_AGENT_CIKTISI}.entities.onay_durumu == false`):**
    a.  EÄžER (`{NIYET_AGENT_CIKTISI}.intent == "TEKLIFI_REDDETME_ALTERNATIF_ISTEME"` VEYA `{NIYET_AGENT_CIKTISI}.intent == "ARAC_SORGU_YENI"`) VE (`{NIYET_AGENT_CIKTISI}.entities.modeller` VEYA `{NIYET_AGENT_CIKTISI}.entities.tipler`) doluysa (Yani kullanÄ±cÄ± reddedip yeni bir ÅŸey sorduysa):
        ```json
        {{
          "kullanici_yaniti_metni": null,
          "teklif_onay_durumu_python_icin": false, 
          "reddedilen_modeller_bu_tur": ["[EÄŸer {ONCEKI_TUR_MODELLERI} listesi doluysa, iÃ§indeki modelleri buraya kÃ¼Ã§Ã¼k harfle, HER BÄ°RÄ°NÄ° AYRI STRÄ°NG OLARAK LÄ°STE Ä°Ã‡Ä°NDE yaz.]"],
          "kullanicinin_yeni_sordugu_modeller": ["[Niyet Agent Ã§Ä±ktÄ±sÄ±ndaki ({NIYET_AGENT_CIKTISI}) 'entities.modeller' veya 'entities.tipler' listesindeki tÃ¼m Ã¶ÄŸeleri buraya ekle]"],
          "sonraki_python_durumu_onerisi": "ARAC_ISLEME_DIREKT_SORGULA",
          "ai_sordu_soru_tipi": "SORU_YOK"
        }}
        ```
    b.  EÄžER `{NIYET_AGENT_CIKTISI}.intent == "TEKLIFI_REDDETME_KAPATMA"`:
        ```json
        {{ "kullanici_yaniti_metni": "AnlÄ±yorum. Vakit ayÄ±rdÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler, iyi gÃ¼nler dilerim.", "teklif_onay_durumu_python_icin": false, "reddedilen_modeller_bu_tur": ["[EÄŸer {ONCEKI_TUR_MODELLERI} listesi doluysa, iÃ§indeki modelleri buraya kÃ¼Ã§Ã¼k harfle, HER BÄ°RÄ°NÄ° AYRI STRÄ°NG OLARAK LÄ°STE Ä°Ã‡Ä°NDE yaz.]"], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "VEDALASMA_ISLEME", "ai_sordu_soru_tipi": "SORU_YOK" }}
        ```
    c.  DÄ°ÄžER REDDETME DURUMLARI (Ã¶rn: genel red, alternatif isteme ama yeni model belirtmeme):
        ```json
        {{ "kullanici_yaniti_metni": "AnladÄ±m. Peki, farklÄ± bir model mi dÃ¼ÅŸÃ¼nÃ¼rsÃ¼nÃ¼z yoksa baÅŸka bir konuda yardÄ±mcÄ± olabilir miyim?", "teklif_onay_durumu_python_icin": false, "reddedilen_modeller_bu_tur": ["[EÄŸer {ONCEKI_TUR_MODELLERI} listesi doluysa, iÃ§indeki modelleri buraya kÃ¼Ã§Ã¼k harfle, HER BÄ°RÄ°NÄ° AYRI STRÄ°NG OLARAK LÄ°STE Ä°Ã‡Ä°NDE yaz.]"], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "ARAC_ISLEME", "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU" }}
        ```
3.  **EÄžER YUKARIDAKÄ° KOÅžULLARIN HÄ°Ã‡BÄ°RÄ° UYMUYORSA (BELÄ°RSÄ°Z YANIT):**
    ```json
    {{
      "kullanici_yaniti_metni": "ÃœzgÃ¼nÃ¼m, tam olarak anlayamadÄ±m. Ã–nceki teklifimizle ilgili miydi, yoksa farklÄ± bir konuda mÄ± yardÄ±mcÄ± olmamÄ± istersiniz?",
      "teklif_onay_durumu_python_icin": null,
      "reddedilen_modeller_bu_tur": [],
      "kullanicinin_yeni_sordugu_modeller": [],
      "sonraki_python_durumu_onerisi": "TEKLIF_YANITI_BEKLENIYOR", 
      "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU"
    }}
    ```
JSON Ã‡IKTI FORMATI (yukarÄ±daki Ã¶rneklerde belirtildiÄŸi gibi):
{{
  "kullanici_yaniti_metni": "[...]", "teklif_onay_durumu_python_icin": true/false/null, "reddedilen_modeller_bu_tur": [], "kullanicinin_yeni_sordugu_modeller": [], "sonraki_python_durumu_onerisi": "[...]", "ai_sordu_soru_tipi": "[...]"
}}
""",
    "FAREWELL_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan nazik bir asistansÄ±n. KullanÄ±cÄ± gÃ¶rÃ¼ÅŸmeyi sonlandÄ±rmak istiyor veya konuÅŸulacak baÅŸka bir konu kalmadÄ±.
SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- MÃ¼ÅŸteri AdÄ± SoyadÄ± (Teyitli veya Orijinal): {MUSTERI_ADI_SOYADI_UNVAN}
KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{KULLANICI_MESAJI}"
Niyet Agent'Ä± Ã‡Ä±ktÄ±sÄ±: {NIYET_AGENT_CIKTISI}
GÃ–REVÄ°N: Kibarca teÅŸekkÃ¼r et ve iyi gÃ¼nler dile.
JSON Ã‡IKTI FORMATI:
{{
  "kullanici_yaniti_metni": "[MÃ¼ÅŸteriye verilecek veda mesajÄ±]",
  "sonraki_python_durumu_onerisi": "GORUSMEYI_BITIR",
  "ai_sordu_soru_tipi": "SORU_YOK"
}}
""",
    "FALLBACK_AGENT": """SENARYO: Sen {COMPANY_NAME} iÃ§in Ã§alÄ±ÅŸan yardÄ±mcÄ± bir asistansÄ±n. KullanÄ±cÄ±nÄ±n son sÃ¶ylediÄŸi net anlaÅŸÄ±lamadÄ± veya sistemin ÅŸu an ele alamayacaÄŸÄ± bir durum oluÅŸtu.
SÄ°STEM BÄ°LGÄ°LERÄ° (Python'dan):
- MÃ¼ÅŸteri AdÄ± SoyadÄ± (Teyitli veya Orijinal): {MUSTERI_ADI_SOYADI_UNVAN}
- KÄ±sa KonuÅŸma GeÃ§miÅŸi: {KONUSMA_GECMISI_FALLBACK}
- AI'Ä±n Ã–nceki AÃ§Ä±klamasÄ± (EÄŸer varsa): {RECENTLY_UNAVAILABLE_MODELS_AI_EXPLANATION}
KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{KULLANICI_MESAJI}"
Niyet Agent'Ä± Ã‡Ä±ktÄ±sÄ±: {NIYET_AGENT_CIKTISI}
GÃ–REVÄ°N:
1.  EÄžER `{NIYET_AGENT_CIKTISI}.intent == "KULLANICI_TUTARSIZLIK_ALGILADI"` Ä°SE:
    KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± dikkate alarak durumu aÃ§Ä±kla: "{KULLANICI_MESAJI}" demiÅŸtiniz. HaklÄ±sÄ±nÄ±z, bir karÄ±ÅŸÄ±klÄ±k olmuÅŸ olabilir. Durumu netleÅŸtireyim: [{RECENTLY_UNAVAILABLE_MODELS_AI_EXPLANATION}]. AmacÄ±m size en uygun seÃ§enekleri sunmaktÄ±r. Hangi modelle ilgili bilgi almak istersiniz ya da nasÄ±l yardÄ±mcÄ± olabilirim?"
2.  EÄžER `{NIYET_AGENT_CIKTISI}.intent == "ANLAMADIM_TEKRAR_ISTEGI"` Ä°SE: Ã–nceki AI mesajÄ±nÄ± farklÄ± kelimelerle tekrar et veya genel yardÄ±m sor.
3.  EÄžER `{NIYET_AGENT_CIKTISI}.intent == "BELIRSIZ_ALAKASIZ"` Ä°SE: Genel yardÄ±m sorusu sor veya konuya dÃ¶nmesini iste.
4.  EÄžER `{NIYET_AGENT_CIKTISI}.intent == "CALISTIGINIZ_MARKALARI_SORMA"` Ä°SE:
    YanÄ±t: "{MUSTERI_ADI_SOYADI_UNVAN}, {COMPANY_NAME} olarak portfÃ¶yÃ¼mÃ¼zde bulunan baÅŸlÄ±ca markalar: {CALISILAN_MARKALAR_STR}. Ã–zellikle ilgilendiÄŸiniz bir marka veya model var mÄ±dÄ±r?" (EÄŸer {CALISILAN_MARKALAR_STR} boÅŸsa, "birÃ§ok popÃ¼ler marka" yerine "Ã§eÅŸitli markalarda araÃ§larÄ±mÄ±z mevcut" de.)
JSON Ã‡IKTI FORMATI:
{{
  "kullanici_yaniti_metni": "[MÃ¼ÅŸteriye verilecek yanÄ±t]",
  "sonraki_python_durumu_onerisi": "[Mevcut Python durumunu koru veya ARAC_ISLEME]",
  "ai_sordu_soru_tipi": "GENEL_YARDIM_SORUSU"
}}
"""
}

async def get_intent_and_entities(user_message: str, short_history: str, known_models_sample: list):
    global async_client, DEBUG_MODE
    if not async_client: return {"intent": "BELIRSIZ_ALAKASIZ", "entities": {}, "error": "Asenkron istemci baÅŸlatÄ±lamadÄ±", "raw_utterance_processed": user_message}
    sample_size = 30
    if len(known_models_sample) > sample_size:
        bilinen_modeller_str = ", ".join(random.sample(known_models_sample, sample_size)) + ", ..."
    else:
        bilinen_modeller_str = ", ".join(known_models_sample)
    prompt_user_for_intent = LLM_DRIVEN_PROMPTS["INTENT_ENTITY_EXTRACTOR"].format(
        BILINEN_MODEL_LISTESI_KISMI=bilinen_modeller_str,
        KONUSMA_GECMISI_KISA=short_history,
        KULLANICI_MESAJI=user_message,
        KULLANICI_MESAJI_TEKRAR=user_message
    )
    system_p = "You are an expert text analysis assistant. Your task is to extract intent and entities from the user's message based on the provided guidelines and output a JSON object."
    if DEBUG_MODE: print(f"\nðŸ•µï¸ Niyet/VarlÄ±k Agent User Prompt (KÄ±smi):\n{prompt_user_for_intent[:600]}...")
    response_str = await safe_openrouter_request_async(
        system_prompt_str=system_p, user_prompt_str=prompt_user_for_intent,
        model_name="meta-llama/llama-guard-4-12b", temperature=0.0, max_tokens=400, expect_json=True
    )
    if "API_ERROR" in response_str:
        return {"intent": "BELIRSIZ_ALAKASIZ", "entities": {}, "error": response_str, "raw_utterance_processed": user_message}
    parsed_data = parse_agent_response_json(response_str, "Niyet/VarlÄ±k Agent")
    if "error" in parsed_data:
        return {"intent": "BELIRSIZ_ALAKASIZ", "entities": {}, "error": parsed_data["error"], "raw_utterance_processed": user_message, "raw_response": parsed_data.get("raw_response")}
    if not (isinstance(parsed_data, dict) and "intent" in parsed_data and "entities" in parsed_data):
        if DEBUG_MODE: print(f"âŒ Niyet/VarlÄ±k Agent YanÄ±tÄ±nda Gerekli Alanlar Yok: {parsed_data}")
        return {"intent": "BELIRSIZ_ALAKASIZ", "entities": {}, "error": "AyrÄ±ÅŸtÄ±rÄ±lan JSON'da niyet/varlÄ±klar eksik", "raw_utterance_processed": user_message, "raw_response": response_str if isinstance(response_str, str) else json.dumps(response_str)}
    entities = parsed_data.get("entities", {})
    if not isinstance(entities, dict):
        if DEBUG_MODE: print(f"âš ï¸ Niyet/VarlÄ±k: 'entities' alanÄ± dict deÄŸil, ÅŸu bulundu: {entities}. BoÅŸ dict ile deÄŸiÅŸtiriliyor.")
        entities = {}
        parsed_data["entities"] = entities
    for key in ["modeller", "markalar", "tipler"]:
        if key in entities and not isinstance(entities[key], list):
            if DEBUG_MODE: print(f"âš ï¸ Niyet/VarlÄ±k: '{key}' alanÄ± liste deÄŸil, string bulundu: {entities[key]}. Tek elemanlÄ± listeye Ã§evriliyor.")
            entities[key] = [str(entities[key])] if entities[key] is not None and str(entities[key]).strip() != "" else []
        elif key not in entities:
             entities[key] = []
    if "onay_durumu" in entities and not isinstance(entities["onay_durumu"], bool) and entities["onay_durumu"] is not None:
        if isinstance(entities["onay_durumu"], str):
            val_lower = entities["onay_durumu"].lower()
            if val_lower == 'true': entities["onay_durumu"] = True
            elif val_lower == 'false': entities["onay_durumu"] = False
            else: entities["onay_durumu"] = None
        elif isinstance(entities["onay_durumu"], int):
            entities["onay_durumu"] = bool(entities["onay_durumu"])
        else: entities["onay_durumu"] = None
    parsed_data["entities"] = entities
    if DEBUG_MODE: print(f"ðŸ•µï¸ Niyet/VarlÄ±k Agent Sonucu (Ä°ÅŸlenmiÅŸ): {parsed_data}")
    return parsed_data

async def execute_task_agent(agent_name_key: str, prompt_format_values: dict,
                             default_model="meta-llama/llama-guard-4-12b",
                             temperature=0.1, max_tokens=400):
    global async_client, DEBUG_MODE, COMPANY_NAME
    if not async_client: return {"error": "Asenkron istemci baÅŸlatÄ±lamadÄ±", "agent_name_key_executed": agent_name_key}
    agent_prompt_template = LLM_DRIVEN_PROMPTS.get(agent_name_key)
    if not agent_prompt_template:
        return {"error": f"{agent_name_key} iÃ§in agent prompt ÅŸablonu bulunamadÄ±.", "agent_name_key_executed": agent_name_key}
    prompt_format_values.setdefault("COMPANY_NAME", COMPANY_NAME)
    prompt_format_values.setdefault("PYTHON_PROVIDED_ALTERNATIVES_TEXT", "Ä°lgili bir alternatif metni bulunamadÄ±.")
    prompt_format_values.setdefault("RECENTLY_UNAVAILABLE_MODELS_CONTEXT", "YakÄ±n zamanda bulunamayan model bilgisi yok.")
    prompt_format_values.setdefault("RECENTLY_UNAVAILABLE_MODELS_AI_EXPLANATION", "Daha Ã¶nce yapÄ±lmÄ±ÅŸ bir AI aÃ§Ä±klamasÄ± yok.")
    prompt_format_values.setdefault("CALISILAN_MARKALAR_STR", "birÃ§ok popÃ¼ler marka")
    try:
        full_prompt_for_agent = agent_prompt_template.format(**prompt_format_values)
    except KeyError as e:
        if DEBUG_MODE: print(f"âŒ {agent_name_key} prompt formatlamada eksik anahtar: {e}. Mevcut anahtarlar: {list(prompt_format_values.keys())}")
        return {"error": f"Prompt formatlamada eksik anahtar: {e}", "agent_name_key_executed": agent_name_key}
    generic_system_prompt = "You are a specialized AI assistant for a vehicle sales company. Follow the instructions in the user prompt carefully and provide your response ONLY in the specified JSON format. Be concise and helpful."
    if DEBUG_MODE:
        print(f"\nðŸ¤– {agent_name_key} Agent'Ä±na GÃ¶nderilen Prompt (KÄ±smi):")
        print(full_prompt_for_agent[:700] + "...")
    response_str = await safe_openrouter_request_async(
        system_prompt_str=generic_system_prompt, user_prompt_str=full_prompt_for_agent,
        model_name=default_model, temperature=temperature, max_tokens=max_tokens, expect_json=True
    )
    if "API_ERROR" in response_str:
        if DEBUG_MODE: print(f"âŒ {agent_name_key} Agent API HatasÄ±: {response_str}")
        return {"error": response_str, "agent_name_key_executed": agent_name_key}
    parsed_data = parse_agent_response_json(response_str, agent_name_key)
    parsed_data["agent_name_key_executed"] = agent_name_key
    if DEBUG_MODE: print(f"ðŸ¤– {agent_name_key} Agent Sonucu: {parsed_data}")
    return parsed_data

def kaydet_onaylar_guncellenmis(user_id, isim, soyisim, onay_verisi_dict):
    # ... (Bu fonksiyon deÄŸiÅŸmedi) ...
    if DEBUG_MODE: print(f"ðŸ’¾ Kaydedilecek Onay/Ret Verisi: User ID: {user_id}, Ä°sim: {isim} {soyisim}, AraÃ§: {onay_verisi_dict.get('marka')} {onay_verisi_dict.get('model')}, Durum: {onay_verisi_dict.get('durum')}, Lokasyon: {onay_verisi_dict.get('sehir')}/{onay_verisi_dict.get('ilce')}")
    log_onay_path = Path("onay_red_kayitlari.csv")
    file_exists = log_onay_path.exists()
    fieldnames = ["timestamp", "user_id", "isim", "soyisim", "marka", "model", "durum", "sehir", "ilce"]
    entry_to_save = {
        "timestamp": datetime.now().isoformat(), "user_id": user_id, "isim": isim, "soyisim": soyisim,
        "marka": onay_verisi_dict.get("marka"), "model": onay_verisi_dict.get("model"),
        "durum": onay_verisi_dict.get("durum"), "sehir": onay_verisi_dict.get("sehir"), "ilce": onay_verisi_dict.get("ilce")
    }
    try:
        with log_onay_path.open("a", newline='', encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            if not file_exists or f.tell() == 0:
                writer.writeheader()
            writer.writerow(entry_to_save)
        if DEBUG_MODE: print(f"âœ… Onay/Ret verisi '{log_onay_path}' dosyasÄ±na eklendi.")
    except Exception as e: print(f"âŒ Onay/Ret verisi CSV'ye yazÄ±lÄ±rken hata: {e}")


async def analiz_et_ve_kaydet_veritabani_async(konusma_gecmisi_str: str, user_id: str, user_final_details: dict):
    # ... (Bu fonksiyon deÄŸiÅŸmedi) ...
    global DEBUG_MODE, async_client
    if DEBUG_MODE: print(f"\nðŸ“Š Son Analiz Agent ile Onay/Ret Tespiti BaÅŸlatÄ±lÄ±yor...")
    sehir = user_final_details.get('sehir', 'Bilinmiyor')
    ilce = user_final_details.get('ilce', 'Bilinmiyor')
    analiz_user_prompt_onay_ret = f"""
Sen bir analiz asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki Ã§aÄŸrÄ± merkezi gÃ¶rÃ¼ÅŸme geÃ§miÅŸini dikkatlice incele.
GÃ¶rÃ¼ÅŸmede adÄ± geÃ§en ve mÃ¼ÅŸteri tarafÄ±ndan bilgi almak iÃ§in ONAYLANAN veya REDDEDÄ°LEN (onaylanmayan/vazgeÃ§ilen/ilgi gÃ¶sterilmeyen) her araÃ§ modelini tespit et.
- EÄŸer mÃ¼ÅŸteri belirli bir model hakkÄ±nda bayi tarafÄ±ndan aranmayÄ± veya daha fazla bilgi almayÄ± net bir ÅŸekilde ONAYLADIYSA, "durum": "onaylandÄ±" yaz.
- EÄŸer mÃ¼ÅŸteri belirli bir modele ilgi gÃ¶stermediyse, reddettiyse veya alternatif arayÄ±ÅŸÄ±na girdiyse, "durum": "onaylanmadÄ±" yaz.
- Sadece konuÅŸma sonunda mÃ¼ÅŸterinin nihai olarak onayladÄ±ÄŸÄ± veya reddettiÄŸi durumlarÄ± listele. AraÅŸtÄ±rÄ±lan ama sonuca baÄŸlanmayan modelleri dahil etme.
- Sonucu aÅŸaÄŸÄ±daki JSON formatÄ±nda bir liste olarak dÃ¶ndÃ¼r. Her bir araÃ§ iÃ§in ayrÄ± bir JSON nesnesi oluÅŸtur.
- JSON nesnesine kullanÄ±cÄ±nÄ±n ÅŸehir ve ilÃ§e bilgisini de ekle.
Format:
[
  {{"marka": "[Marka AdÄ±]", "model": "[Model AdÄ±]", "durum": "onaylandÄ±", "sehir": "{sehir}", "ilce": "{ilce}"}},
  {{"marka": "[DiÄŸer Marka]", "model": "[DiÄŸer Model]", "durum": "onaylanmadÄ±", "sehir": "{sehir}", "ilce": "{ilce}"}}
]
EÄŸer net bir nihai onay veya ret yoksa, boÅŸ bir liste dÃ¶ndÃ¼r: []
GÃ¶rÃ¼ÅŸme geÃ§miÅŸi:
{konusma_gecmisi_str}"""
    analiz_system_prompt = "Sen bir gÃ¶rÃ¼ÅŸme analiz asistanÄ±sÄ±n. KonuÅŸmayÄ± analiz edip, mÃ¼ÅŸterinin hangi araÃ§lar iÃ§in bilgi almayÄ± onayladÄ±ÄŸÄ±nÄ± veya reddettiÄŸini JSON formatÄ±nda bir liste olarak Ã§Ä±karÄ±rsÄ±n."
    if DEBUG_MODE: print(f"\nðŸ“Š Son Analiz Agent Prompt (Onay/Ret):\n{analiz_user_prompt_onay_ret[:700]}...")
    response_content = await safe_openrouter_request_async(
        system_prompt_str=analiz_system_prompt, user_prompt_str=analiz_user_prompt_onay_ret,
        model_name="meta-llama/llama-guard-4-12b", temperature=0.0, max_tokens=1024, expect_json=True)
    if "API_ERROR" in response_content:
        print(f"âŒ Son Onay/Ret Analiz API hatasÄ±: {response_content}"); return
    if DEBUG_MODE: print(f"\nðŸ“Š Son Analiz Agent Ham DÃ¶nÃ¼ÅŸÃ¼ (Onay/Ret):\n{response_content}")
    json_liste = parse_agent_response_json(response_content, "Son Onay/Ret Analiz Agent")
    if isinstance(json_liste, dict) and "error" in json_liste:
        print(f"âŒ Son Onay/Ret Analiz Pars Etme HatasÄ±: {json_liste.get('error')}")
        if DEBUG_MODE and "raw_response" in json_liste: print(f"  Ham yanÄ±t: {json_liste['raw_response']}")
        return
    if not isinstance(json_liste, list):
        print(f"âŒ Son Onay/Ret Analiz yanÄ±tÄ± beklenen liste formatÄ±nda deÄŸil, alÄ±nan: {type(json_liste)}. YanÄ±t: {json_liste}")
        json_liste = []
    if not json_liste and DEBUG_MODE: print("â„¹ï¸ Son analizde onaylanan/reddedilen araÃ§ bulunamadÄ±.")
    for onay_verisi in json_liste:
        if isinstance(onay_verisi, dict) and all(k in onay_verisi for k in ["marka", "model", "durum"]):
            onay_verisi.setdefault("sehir", sehir); onay_verisi.setdefault("ilce", ilce)
            kaydet_onaylar_guncellenmis(user_id, user_final_details.get("isim", "Bilinmiyor"), user_final_details.get("soyisim", ""), onay_verisi)
        elif DEBUG_MODE:
            print(f"âš ï¸ Son Analiz: Eksik formatta onay verisi atlandÄ±: {onay_verisi}")

def get_unique_brands_from_models(df_vehicles_input: pd.DataFrame,
                                  recommendation_columns: list = None,
                                  output_dir: str = "arac_analizi_raporlari",
                                  save_files: bool = False) -> list:
    # ... (Bu fonksiyon deÄŸiÅŸmedi, ileride kullanÄ±lacak) ...
    global DEBUG_MODE
    if df_vehicles_input is None or df_vehicles_input.empty:
        if DEBUG_MODE: print("Hata: get_unique_brands_from_models - GiriÅŸ DataFrame'i boÅŸ veya None.")
        return []
    if recommendation_columns is None:
        recommendation_columns = ['eÅŸ deÄŸeri', 'elektrikli', 'Ã¶neri3', 'Ã¶neri4', 'Ã¶neri5']
    if save_files:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            if DEBUG_MODE: print(f"\n'{output_dir}' dizini oluÅŸturuldu.")
    all_unique_models_from_recommendations = set()
    for col_name in recommendation_columns:
        if col_name in df_vehicles_input.columns:
            unique_models_in_col = df_vehicles_input[col_name].dropna().astype(str).str.strip()
            unique_models_in_col = unique_models_in_col[unique_models_in_col.str.lower() != 'none']
            unique_models_in_col = unique_models_in_col[unique_models_in_col != ''].unique()
            all_unique_models_from_recommendations.update(unique_models_in_col)
            if save_files and len(unique_models_in_col) > 0:
                df_unique_col_models = pd.DataFrame(sorted(list(unique_models_in_col)), columns=['unique_vehicle_model'])
                safe_col_name = re.sub(r'[^a-zA-Z0-9_]', '', col_name)
                output_col_filename = os.path.join(output_dir, f"benzersiz_onerilen_modeller_{safe_col_name}.csv")
                try:
                    df_unique_col_models.to_csv(output_col_filename, index=False, encoding='utf-8')
                except Exception as e:
                    if DEBUG_MODE: print(f"HATA: {output_col_filename} dosyasÄ± yazÄ±lÄ±rken sorun oluÅŸtu: {e}")
        elif DEBUG_MODE:
            print(f"UyarÄ±: '{col_name}' sÃ¼tunu Ã¶neri analizi iÃ§in DataFrame'de bulunamadÄ±.")
    derived_brands = set()
    for model_name_full in all_unique_models_from_recommendations:
        model_name = str(model_name_full).strip()
        if model_name:
            brand_candidate = model_name.split(' ')[0].lower()
            if brand_candidate:
                derived_brands.add(brand_candidate.capitalize())
    sorted_unique_brands = sorted(list(derived_brands))
    if save_files and sorted_unique_brands:
        df_final_unique_brands = pd.DataFrame(sorted_unique_brands, columns=['unique_brand_name'])
        output_brands_filename = os.path.join(output_dir, "tum_benzersiz_turetilmis_markalar.csv")
        try:
            df_final_unique_brands.to_csv(output_brands_filename, index=False, encoding='utf-8')
        except Exception as e:
            if DEBUG_MODE: print(f"HATA: {output_brands_filename} dosyasÄ± yazÄ±lÄ±rken sorun oluÅŸtu: {e}")
    elif save_files and not sorted_unique_brands and DEBUG_MODE:
        print("Kaydedilecek tÃ¼retilmiÅŸ benzersiz marka bulunamadÄ±.")
    return sorted_unique_brands

async def main_async_llm_driven():
    global session_rejected_models, fuzzy_matching_model_library_list, DEBUG_MODE, async_client, konusma_gecmisi_log_tamami, COMPANY_NAME, df_vehicles

    debug_input = input("Debug modunu aktif etmek ister misiniz? (evet/hayÄ±r): ").lower()
    DEBUG_MODE = True if debug_input == "evet" else False
    print(f"--- DEBUG MODU {'AKTÄ°F' if DEBUG_MODE else 'KAPALI'} ---")

    if not load_external_model_library_from_csv():
        print("UYARI: Harici model kÃ¼tÃ¼phanesi yÃ¼klenemedi. Model tanÄ±ma yetenekleri sÄ±nÄ±rlÄ± olabilir.")

    print("ðŸ“ž Aramak istediÄŸin kiÅŸinin ID'sini seÃ§:")
    for i, user_profile_item in enumerate(kullanicilar):
        print(f"{i}: {user_profile_item['isim']} {user_profile_item['soyisim']} - {user_profile_item.get('marka','Marka Yok')} {user_profile_item.get('model','Model Yok')}")

    selected_id_str = input("ID gir: ")
    try:
        original_user_profile = next((u for u in kullanicilar if u["id"] == selected_id_str), None)
        if not original_user_profile:
            selected_id_int_fallback = int(selected_id_str)
            if 0 <= selected_id_int_fallback < len(kullanicilar):
                original_user_profile = kullanicilar[selected_id_int_fallback]
            else: raise ValueError("ID bulunamadÄ±")
    except (ValueError, IndexError):
        print("âŒ GeÃ§ersiz ID. Program sonlandÄ±rÄ±lÄ±yor."); return

    current_user_details = original_user_profile.copy()
    current_user_details['original_isim'] = original_user_profile['isim']
    current_user_details['original_soyisim'] = original_user_profile['soyisim']
    current_user_details["isim_teyit_edildi"] = False
    current_user_details['pending_models_for_alternatives'] = []
    current_user_details['recently_unavailable_direct_query_info'] = None

    session_rejected_models = []
    konusma_gecmisi_log_tamami = ""
    gecmis_mesajlar_list_llm_icin = []

    current_orchestrator_state = "KIMLIK_DOGRULAMA_BASLANGIC"
    ai_last_question_type = "KIMLIK_TEYIT_SORUSU"

    _intent_for_next_turn = None
    _entities_for_next_turn = None
    _user_input_for_next_turn_context = None
    session_last_offered_models = []

    user_isim_unvan_ilk = f"{current_user_details['isim']} {current_user_details.get('unvan', get_unvan(current_user_details['isim']))}"

    selamlama_system_prompt = f"You are a call center assistant for {COMPANY_NAME}, a new vehicle sales company. Your task is to make the initial greeting. You are calling the customer for the first time."
    selamlama_user_prompt = f"Politely introduce that you are calling from {COMPANY_NAME}. Then, directly ask to confirm if the person you have called is indeed '{user_isim_unvan_ilk}'. For example, the question part in Turkish should be similar to '... {user_isim_unvan_ilk} ile mi gÃ¶rÃ¼ÅŸÃ¼yorum?'. Your entire response must be a single, short, and natural-sounding sentence in Turkish."
    ai_message_text = await safe_openrouter_request_async(
        system_prompt_str=selamlama_system_prompt, user_prompt_str=selamlama_user_prompt,
        model_name="meta-llama/llama-guard-4-12b", temperature=0.3, max_tokens=100 )
    fallback_greeting = f"Merhaba, {COMPANY_NAME}'dan arÄ±yorum. {user_isim_unvan_ilk} ile mi gÃ¶rÃ¼ÅŸÃ¼yorum?"
    if "API_ERROR" in ai_message_text or not ai_message_text.strip():
        ai_message_text = fallback_greeting
        if DEBUG_MODE: print(f"âš ï¸ LLM ilk selamlama iÃ§in yanÄ±t veremedi, fallback kullanÄ±lÄ±yor.")
    else:
        ai_message_text = ai_message_text.strip().split('\n')[0]
        user_name_check = original_user_profile['isim']
        if (f"ben {user_name_check.lower()}" in ai_message_text.lower() and ai_message_text.endswith("?")) or \
           (f"adÄ±m {user_name_check.lower()}" in ai_message_text.lower() and ai_message_text.endswith("?")) or \
           (f" {user_name_check.lower()}'im mi" in ai_message_text.lower()) or \
           (f" {user_name_check.lower()} miyim" in ai_message_text.lower()):
            if DEBUG_MODE: print(f"âš ï¸ LLM ilk selamlamada hatalÄ± kimlik sorgusu yaptÄ± ('{ai_message_text}'), fallback kullanÄ±lÄ±yor.")
            ai_message_text = fallback_greeting

    print(f"\n{datetime.now().strftime('%H:%M:%S')} ðŸ§  AI: {ai_message_text}")
    konusma_gecmisi_log_tamami += f"AI: {ai_message_text}"
    gecmis_mesajlar_list_llm_icin.append({"role": "assistant", "content": ai_message_text})
    user_input_text = ""

    while True:
        if DEBUG_MODE:
            print(f"\nðŸ”„ ORKESTRATÃ–R TUR BAÅžI: Durum: {current_orchestrator_state} | Reddedilenler: {session_rejected_models} | Ã–nceki AI Soru: {ai_last_question_type} | Bekleyen Alt Sorgu: {current_user_details.get('pending_models_for_alternatives')}")
            print(f"    _intent_for_next_turn: {_intent_for_next_turn}, _entities_for_next_turn: {_entities_for_next_turn}, _user_input_for_next_turn_context: '{_user_input_for_next_turn_context}'")
            print(f"    session_last_offered_models: {session_last_offered_models}")
            print(f"    current_user_details['recently_unavailable_direct_query_info']: {current_user_details.get('recently_unavailable_direct_query_info')}")

        user_input_text_this_turn = ""
        intent_entity_result = {}
        user_input_text_to_use_in_prompt = ""
        detected_intent = "BELIRSIZ_ALAKASIZ"
        detected_entities = {"modeller": [], "markalar": [], "tipler": [], "isim_soyisim": None, "onay_durumu": None}

        if current_orchestrator_state in ["ARAC_ISLEME_DIREKT_SORGULA", "GENEL_ONERI_ISTEGI_DIREKT_SUN"] and _intent_for_next_turn:
            if DEBUG_MODE: print(f"â„¹ï¸ Direkt aksiyon durumu: {current_orchestrator_state}. Ã–nceden ayarlanmÄ±ÅŸ niyet ('{_intent_for_next_turn}') ve varlÄ±klar kullanÄ±lacak.")
            detected_intent = _intent_for_next_turn
            detected_entities = _entities_for_next_turn if _entities_for_next_turn else detected_entities
            user_input_text_to_use_in_prompt = _user_input_for_next_turn_context if _user_input_for_next_turn_context else "DoÄŸrudan eylem."
            intent_entity_result = {"intent": detected_intent, "entities": detected_entities, "raw_utterance_processed": user_input_text_to_use_in_prompt}
            if DEBUG_MODE: print(f"    Direkt aksiyon iÃ§in hazÄ±rlanan intent_entity_result: {intent_entity_result}")
            _intent_for_next_turn = None
            _entities_for_next_turn = None
            _user_input_for_next_turn_context = None
        else:
            current_user_display_name = f"{current_user_details['isim']} {current_user_details.get('unvan', get_unvan(current_user_details['isim']))}"
            if not current_user_details.get("isim_teyit_edildi"):
                current_user_display_name = f"{original_user_profile['isim']} {original_user_profile.get('unvan', get_unvan(original_user_profile['isim']))}"
            user_input_text_this_turn = input(f"{datetime.now().strftime('%H:%M:%S')} ðŸ—£ï¸  {current_user_display_name}: ").strip()
            user_input_text = user_input_text_this_turn
            user_input_text_to_use_in_prompt = user_input_text_this_turn
            if user_input_text.lower() == 'Ã§Ä±kÄ±ÅŸ' or not user_input_text_this_turn :
                print("\nðŸ‘‹ KullanÄ±cÄ± Ã§Ä±kÄ±ÅŸ yaptÄ± veya boÅŸ giriÅŸ yaptÄ±.")
                konusma_gecmisi_log_tamami += f"\nUser ({current_user_display_name}): {user_input_text_this_turn if user_input_text_this_turn else '[BOÅž GÄ°RDÄ°/Ã‡IKIÅž]'}"
                current_orchestrator_state = "GORUSMEYI_BITIR"
                break
            konusma_gecmisi_log_tamami += f"\nUser ({current_user_display_name}): {user_input_text_this_turn}"
            gecmis_mesajlar_list_llm_icin.append({"role": "user", "content": user_input_text_this_turn})
            short_history_for_intent = format_structured_history(gecmis_mesajlar_list_llm_icin[-6:], turns=3)
            intent_entity_result = await get_intent_and_entities(user_input_text_this_turn, short_history_for_intent, fuzzy_matching_model_library_list)
            detected_intent = intent_entity_result.get("intent", "BELIRSIZ_ALAKASIZ")
            raw_entities = intent_entity_result.get("entities")
            if isinstance(raw_entities, dict):
                detected_entities = {
                    "modeller": raw_entities.get("modeller", []), "markalar": raw_entities.get("markalar", []),
                    "tipler": raw_entities.get("tipler", []), "isim_soyisim": raw_entities.get("isim_soyisim"),
                    "onay_durumu": raw_entities.get("onay_durumu")}
            else:
                 detected_entities = {"modeller": [], "markalar": [], "tipler": [], "isim_soyisim": None, "onay_durumu": None}
                 if DEBUG_MODE: print(f"âš ï¸ NLU'dan gelen 'entities' alanÄ± bir sÃ¶zlÃ¼k deÄŸil: {raw_entities}")
            if "error" in intent_entity_result and DEBUG_MODE:
                 print(f"âŒ Niyet/VarlÄ±k Agent HatasÄ±: {intent_entity_result.get('error')}")

        ai_message_text = "ÃœzgÃ¼nÃ¼m, bir karÄ±ÅŸÄ±klÄ±k oldu. Ne demek istediÄŸinizi tam anlayamadÄ±m."
        next_turn_orchestrator_state_suggestion = current_orchestrator_state
        agent_response_data = None

        prompt_format_values = {
            "MUSTERI_ADI_SOYADI_UNVAN": f"{current_user_details['isim']} {current_user_details.get('unvan', get_unvan(current_user_details['isim']))}",
            "ORIJINAL_PROFIL_BILGISI": f"Ä°sim: {original_user_profile['isim']} {original_user_profile['soyisim']}, AraÃ§: {original_user_profile.get('marka','')} {original_user_profile.get('model','')}",
            "ORIGINAL_PROFILE_ISIM": original_user_profile['isim'],
            "KULLANICI_MESAJI": user_input_text_to_use_in_prompt,
            "NIYET_AGENT_CIKTISI": intent_entity_result,
            "ONCEKI_AI_SORU_TIPI": ai_last_question_type,
            "ISIM_TEYIT_EDILDI_MI": current_user_details.get("isim_teyit_edildi", False),
            "REDDEDILEN_MODELLER": str(list(set(str(m).lower() for m in session_rejected_models))),
            "KONUSMA_GECMISI_FALLBACK": format_structured_history(gecmis_mesajlar_list_llm_icin[-6:], turns=3),
            "DETECTED_INTENT": detected_intent,
            "PYTHON_PROVIDED_ALTERNATIVES_TEXT": "Ä°lgili bir alternatif metni bulunamadÄ±.",
            "ONCEKI_TUR_MODELLERI": str(session_last_offered_models) if session_last_offered_models else "Belirli bir model konuÅŸulmadÄ±.",
            "RECENTLY_UNAVAILABLE_MODELS_CONTEXT": "YakÄ±n zamanda bulunamayan model bilgisi yok.",
            "RECENTLY_UNAVAILABLE_MODELS_AI_EXPLANATION": "Daha Ã¶nce yapÄ±lmÄ±ÅŸ bir AI aÃ§Ä±klamasÄ± yok.",
            "KULLANICININ_SORDUGU_MODELLER_VE_TIPLER": str(detected_entities.get("modeller", []) + detected_entities.get("tipler", [])),
            "CALISILAN_MARKALAR_STR": "birÃ§ok popÃ¼ler marka"
        }
        recently_unavailable_info = current_user_details.get('recently_unavailable_direct_query_info')
        if recently_unavailable_info:
            prompt_format_values["RECENTLY_UNAVAILABLE_MODELS_CONTEXT"] = f"KullanÄ±cÄ± daha Ã¶nce '{recently_unavailable_info['model']}' modelini sordu ve AI'dan '{recently_unavailable_info['ai_explanation']}' ÅŸeklinde bir yanÄ±t almÄ±ÅŸtÄ±."
            prompt_format_values["RECENTLY_UNAVAILABLE_MODELS_AI_EXPLANATION"] = f"KullanÄ±cÄ± '{recently_unavailable_info['model']}' sorduÄŸunda AI ÅŸu yanÄ±tÄ± vermiÅŸti: '{recently_unavailable_info['ai_explanation']}'"
        if not isinstance(prompt_format_values["NIYET_AGENT_CIKTISI"].get("entities"), dict):
            if DEBUG_MODE: print(f"âš ï¸ Niyet Agent Ã‡Ä±ktÄ±sÄ± 'entities' alanÄ± dict deÄŸil, dÃ¼zeltiliyor (orkestratÃ¶rde). Ã‡Ä±ktÄ±: {prompt_format_values['NIYET_AGENT_CIKTISI']}")
            prompt_format_values["NIYET_AGENT_CIKTISI"]["entities"] = {"modeller": [], "markalar": [], "tipler": [], "isim_soyisim": None, "onay_durumu": None}

        # ==============================================================================
        # ORCHESTRATOR LOGIC - ROUTING TO TASK AGENTS
        # ==============================================================================
        # *** YENÄ°: TEKLIF_YANITI_BEKLENIYOR durumunda kullanÄ±cÄ± yeni soru sorarsa Ã¶nceliklendir ***
        if current_orchestrator_state == "TEKLIF_YANITI_BEKLENIYOR":
            question_intents = ["ARAC_SORGU_YENI", "ARAC_SORGU_DETAY_FIYAT",
                                "GENEL_ONERI_ISTEGI", "KULLANICI_TUTARSIZLIK_ALGILADI",
                                "CALISTIGINIZ_MARKALARI_SORMA", "ANLAMADIM_TEKRAR_ISTEGI"]
            is_new_query_or_issue = detected_intent in question_intents
            # NLU'nun onay_durumu: null dÃ¶ndÃ¼rmesi kritik. True ise, kullanÄ±cÄ± teklifi onaylÄ±yor demektir.
            nlu_indicates_not_confirmed_or_new_query = intent_entity_result.get("entities", {}).get("onay_durumu") is not True

            if is_new_query_or_issue and nlu_indicates_not_confirmed_or_new_query:
                if DEBUG_MODE:
                    print(f"â„¹ï¸ TEKLIF_YANITI_BEKLENIYOR durumunda kullanÄ±cÄ± yeni bir soru/durum belirtti ({detected_intent}).")
                    print(f"    Ã–nceki teklif ({session_last_offered_models}) zÄ±mnen reddedilmiÅŸ sayÄ±lÄ±yor.")
                if session_last_offered_models:
                    for m_rej_text in session_last_offered_models:
                        models_to_reject_from_item = [m.strip().lower() for m in str(m_rej_text).split(',') if m.strip()]
                        for m_lower in models_to_reject_from_item:
                            if m_lower and m_lower not in session_rejected_models:
                                session_rejected_models.append(m_lower)
                                if DEBUG_MODE: print(f"ðŸš« Model ('{m_lower}') TEKLIF_YANITI_BEKLENIYOR'da yeni soru Ã¼zerine reddedilenlere eklendi.")
                    session_last_offered_models = []
                _intent_for_next_turn = detected_intent
                _entities_for_next_turn = detected_entities
                _user_input_for_next_turn_context = user_input_text_to_use_in_prompt
                next_direct_state = "ARAC_ISLEME"
                if detected_intent in ["ARAC_SORGU_YENI", "ARAC_SORGU_DETAY_FIYAT"]: next_direct_state = "ARAC_ISLEME_DIREKT_SORGULA"
                elif detected_intent == "GENEL_ONERI_ISTEGI": next_direct_state = "GENEL_ONERI_ISTEGI_DIREKT_SUN"
                agent_response_data = {"kullanici_yaniti_metni": None, "sonraki_python_durumu_onerisi": next_direct_state,
                                       "ai_sordu_soru_tipi": "SORU_YOK", "agent_name_key_executed": "ORCHESTRATOR_IMPLICIT_REJECTION_HANDLER"}
            else: # KullanÄ±cÄ± doÄŸrudan teklife yanÄ±t veriyor
                pending_alts_for_models = current_user_details.get('pending_models_for_alternatives', [])
                if ai_last_question_type == "ALTERNATIF_SUNMA_ONAY_SORUSU" and detected_intent == "TEKLIFI_ONAYLAMA" and \
                   pending_alts_for_models and intent_entity_result.get("entities",{}).get("onay_durumu") == True:
                    if DEBUG_MODE: print(f"ðŸ‘ KullanÄ±cÄ± '{','.join(pending_alts_for_models)}' iÃ§in alternatifleri onayladÄ±...")
                    alternatives_found_parts = []; unique_alternatives_suggested = set()
                    for model_orig_lower in pending_alts_for_models:
                        alt_result = suggest_vehicle_alternative(model_orig_lower, df_vehicles)
                        if alt_result and alt_result.get("Ã¶neri") and alt_result.get("Ã¶neri") not in unique_alternatives_suggested:
                            alternatives_found_parts.append(f"{str(model_orig_lower).capitalize()} yerine {str(alt_result.get('Ã¶neri')).capitalize()}")
                            unique_alternatives_suggested.add(alt_result.get("Ã¶neri").lower())
                    prompt_format_values["PYTHON_PROVIDED_ALTERNATIVES_TEXT"] = f"Elbette. {', '.join(alternatives_found_parts)} modellerini Ã¶nerebilirim." if alternatives_found_parts else "Peki, sizin iÃ§in alternatif modellere baktÄ±m ancak ÅŸu anda spesifik bir Ã¶neri oluÅŸturamadÄ±m."
                agent_response_data = await execute_task_agent("OFFER_RESPONSE_HANDLER_AGENT", prompt_format_values)
                current_user_details['pending_models_for_alternatives'] = []
                if DEBUG_MODE: print(f"â„¹ï¸ Bekleyen alternatif sorgusu temizlendi (OFFER_RESPONSE_HANDLER Ã§aÄŸrÄ±sÄ± sonrasÄ±).")
        elif detected_intent == "NEREDEN_ARADINIZ_SORUSU":
            company_intro = f"Ben {COMPANY_NAME}'dan arÄ±yorum."
            q_type_for_next = "KIMLIK_TEYIT_SORUSU"; state_for_next = "KIMLIK_DOGRULAMA_BASLANGIC"
            msg_text_for_who_are_you = f"{company_intro} {original_user_profile['isim']} {get_unvan(original_user_profile['isim'])} ile mi gÃ¶rÃ¼ÅŸÃ¼yorum?" if not current_user_details.get("isim_teyit_edildi") else f"{company_intro}, {current_user_details['isim']} {get_unvan(current_user_details['isim'])}. Size nasÄ±l yardÄ±mcÄ± olabilirim?"
            if current_user_details.get("isim_teyit_edildi"): q_type_for_next = "GENEL_YARDIM_SORUSU"; state_for_next = "ARAC_ISLEME"
            agent_response_data = {"kullanici_yaniti_metni": msg_text_for_who_are_you, "sonraki_python_durumu_onerisi": state_for_next, "ai_sordu_soru_tipi": q_type_for_next, "agent_name_key_executed": "INTERNAL_WHO_ARE_YOU_HANDLER"}
        elif current_orchestrator_state == "KIMLIK_DOGRULAMA_BASLANGIC" or \
             (not current_user_details.get("isim_teyit_edildi") and \
              detected_intent in ["KIMLIK_ONAYLAMA", "KIMLIK_DUZELTME_ISIM_VERME", "KIMLIK_REDDETME_GENEL"]):
            # *** DEÄžÄ°ÅžÄ°KLÄ°K: PROFIL_ARACI_ANALIZI iÃ§in kullanÄ±cÄ± dostu metin ***
            profil_araci_user_friendly_str = ""
            if original_user_profile.get('marka') and original_user_profile.get('model'):
                _profil_araci_tam = f"{original_user_profile.get('marka')} {original_user_profile.get('model')}".lower().strip()
                if _profil_araci_tam and _profil_araci_tam != 'none':
                    sonuc_profil_araci = suggest_vehicle_alternative(_profil_araci_tam, df_vehicles)
                    if sonuc_profil_araci and sonuc_profil_araci.get('Ã¶neri'):
                        if sonuc_profil_araci.get('durum') == 1: # Ã‡eviri -> EÅŸdeÄŸer
                            profil_araci_user_friendly_str = f"AradÄ±ÄŸÄ±nÄ±z '{str(sonuc_profil_araci.get('bulunan')).capitalize()}' modeline ({str(sonuc_profil_araci.get('bulunan')).capitalize()} olarak kayÄ±tlÄ±) alternatif olarak '{str(sonuc_profil_araci.get('Ã¶neri')).capitalize()}' modelini Ã¶nerebiliriz."
                        elif sonuc_profil_araci.get('durum') == 2: # DoÄŸrudan mevcut
                             profil_araci_user_friendly_str = f"Evet, '{str(sonuc_profil_araci.get('Ã¶neri')).capitalize()}' modelimiz mevcut." # Profil aracÄ± = Ã¶neri
                        elif sonuc_profil_araci.get('durum') == 3: # Alternatif Ã¶neri
                            profil_araci_user_friendly_str = f"AradÄ±ÄŸÄ±nÄ±z '{str(sonuc_profil_araci.get('bulunan')).capitalize()}' modeli iÃ§in size alternatif olarak '{str(sonuc_profil_araci.get('Ã¶neri')).capitalize()}' modelini Ã¶nerebiliriz."
                        elif sonuc_profil_araci.get('durum') == 4: # BulunamadÄ±
                             profil_araci_user_friendly_str = f"AradÄ±ÄŸÄ±nÄ±z '{str(sonuc_profil_araci.get('bulunan')).capitalize()}' modeli iÃ§in ÅŸu anda uygun bir alternatifimiz bulunmuyor."
            prompt_format_values["PROFIL_ARACI_ANALIZI"] = profil_araci_user_friendly_str if profil_araci_user_friendly_str else "" # BoÅŸ yolla ki agent ona gÃ¶re davransÄ±n
            # *** DEÄžÄ°ÅžÄ°KLÄ°K SONU ***
            agent_response_data = await execute_task_agent("IDENTITY_HANDLER_AGENT", prompt_format_values)
            if agent_response_data and "error" not in agent_response_data:
                agent_karari = agent_response_data.get("agent_karari"); g_isim_soyisim = agent_response_data.get("guncellenmis_isim_soyisim")
                if agent_karari == "ONAYLANDI":
                    current_user_details.update(original_user_profile); current_user_details["isim_teyit_edildi"] = True
                    if DEBUG_MODE: print(f"ðŸ“ Kimlik ONAYLANDI ({current_user_details['isim']}).")
                elif agent_karari in ["DUZELTILDI_FARKLI_KISI", "YENI_KISI_TANIMLANDI"]:
                    if g_isim_soyisim:
                        parts = str(g_isim_soyisim).split(" ", 1); current_user_details['isim'] = parts[0].capitalize(); current_user_details['soyisim'] = parts[1].capitalize() if len(parts) > 1 else ""; current_user_details['unvan'] = get_unvan(current_user_details['isim']); current_user_details["isim_teyit_edildi"] = True
                        current_user_details['marka'] = None; current_user_details['model'] = None
                        if DEBUG_MODE: print(f"ðŸ“ Kimlik YENÄ° KÄ°ÅžÄ°/DÃœZELTÄ°LDÄ°: {current_user_details['isim']} {current_user_details['soyisim']}.")
        elif current_user_details.get("isim_teyit_edildi"):
            if detected_intent in ["ARAC_SORGU_YENI", "ARAC_SORGU_DETAY_FIYAT"]:
                python_arac_analizi_str_lines = [];
                sordugu_modeller_ve_tipler_entity = detected_entities.get("modeller", []) + detected_entities.get("tipler", [])
                if not sordugu_modeller_ve_tipler_entity and user_input_text_this_turn:
                    sordugu_modeller_ve_tipler_entity = find_models_in_text_from_library(user_input_text_this_turn, fuzzy_matching_model_library_list)
                processed_items_for_agent = set()
                current_user_details['recently_unavailable_direct_query_info'] = None
                for item_s in sordugu_modeller_ve_tipler_entity:
                    item_s_lower = str(item_s).lower().strip()
                    if not item_s_lower or item_s_lower in processed_items_for_agent: continue
                    processed_items_for_agent.add(item_s_lower)
                    if item_s_lower not in ["elektrikli", "dizel", "benzinli", "suv", "sedan", "hatchback", "otomatik", "manuel"]:
                        sonuc = suggest_vehicle_alternative(item_s_lower, df_vehicles)
                        python_arac_analizi_str_lines.append(f"- Talep Edilen '{str(sonuc.get('bulunan')).capitalize()}': Durum {sonuc.get('durum')}, Ã–neri: {str(sonuc.get('Ã¶neri')).capitalize() if sonuc.get('Ã¶neri') else 'Yok'}, Excelde Var: {sonuc.get('excelde_var')}, AÃ§Ä±klama: {sonuc.get('mesaj')}")
                        if sonuc.get('durum') in [3, 4]: current_user_details['recently_unavailable_direct_query_info'] = {"model": item_s_lower, "ai_explanation": sonuc.get('mesaj')}
                    else: python_arac_analizi_str_lines.append(f"- Talep Edilen AraÃ§ Tipi/Ã–zelliÄŸi: '{item_s_lower.capitalize()}'.")
                prompt_format_values["PYTHON_ARAC_ANALIZ_SONUCLARI"] = "\n".join(python_arac_analizi_str_lines) if python_arac_analizi_str_lines else "- KullanÄ±cÄ±nÄ±n sorguladÄ±ÄŸÄ± modeller/tipler iÃ§in Ã¶zel Python analizi bulunamadÄ± veya bir model/tip belirtilmedi."
                prompt_format_values["KULLANICININ_SORDUGU_MODELLER_VE_TIPLER"] = str(list(processed_items_for_agent)) if processed_items_for_agent else "Belirtilmedi"
                agent_response_data = await execute_task_agent("VEHICLE_INQUIRY_AGENT", prompt_format_values)
                if agent_response_data and not agent_response_data.get("error"):
                    if agent_response_data.get("ai_sordu_soru_tipi") == "ALTERNATIF_SUNMA_ONAY_SORUSU": # VEHICLE_INQUIRY_AGENT bunu artÄ±k sormuyor, direkt ARAC_ILGI_SORUSU soruyor.
                        unavailable_from_agent_list = agent_response_data.get("unavailable_models_queried", [])
                        if unavailable_from_agent_list: current_user_details['pending_models_for_alternatives'] = [m.lower() for m in unavailable_from_agent_list]
                    elif current_user_details['pending_models_for_alternatives']: current_user_details['pending_models_for_alternatives'] = []
            elif detected_intent == "GENEL_ONERI_ISTEGI":
                all_possible_suggestions = []
                for col_suggest in ['eÅŸ deÄŸeri', 'elektrikli', 'Ã¶neri3', 'Ã¶neri4', 'Ã¶neri5']:
                    if col_suggest in df_vehicles.columns:
                        models_in_col_suggest = df_vehicles[col_suggest].dropna().astype(str).str.lower().str.strip().unique()
                        all_possible_suggestions.extend([m for m in models_in_col_suggest if m and m != 'none'])
                valid_suggestions = [m.capitalize() for m in sorted(list(set(all_possible_suggestions))) if m not in session_rejected_models]
                Ã¶neri_listesi_str = ("Mevcut modellerimizden bazÄ±larÄ±: " + ", ".join(random.sample(valid_suggestions, min(len(valid_suggestions), 3)))) if valid_suggestions else "Åžu an iÃ§in size Ã¶zel bir Ã¶neri listesi hazÄ±rlayamadÄ±m."
                prompt_format_values["PYTHON_GENEL_ONERI_LISTESI"] = Ã¶neri_listesi_str
                prompt_format_values["KONUSULAN_REDDEDILEN_MODELLER"] = f"Daha Ã¶nce konuÅŸulanlar (son mesajlar): {format_structured_history(gecmis_mesajlar_list_llm_icin[-5:], turns=2)}\nReddedilenler: {str(session_rejected_models)}"
                agent_response_data = await execute_task_agent("GENERAL_RECOMMENDATION_AGENT", prompt_format_values)
                current_user_details['recently_unavailable_direct_query_info'] = None
            elif detected_intent == "CALISTIGINIZ_MARKALARI_SORMA":
                # available_brands_list = get_unique_brands_from_models(df_vehicles) # Aktif edilecek
                # prompt_format_values["CALISILAN_MARKALAR_STR"] = ", ".join(available_brands_list) if available_brands_list else "birÃ§ok popÃ¼ler marka"
                agent_response_data = await execute_task_agent("FALLBACK_AGENT", prompt_format_values)
            elif detected_intent == "VEDALASMA_KAPATMA":
                agent_response_data = await execute_task_agent("FAREWELL_AGENT", prompt_format_values)
            elif detected_intent in ["ANLAMADIM_TEKRAR_ISTEGI", "KULLANICI_TUTARSIZLIK_ALGILADI", "BELIRSIZ_ALAKASIZ"]:
                if DEBUG_MODE: print(f"DEFANSÄ°F (kimlik sonrasÄ±): Niyet '{detected_intent}' Fallback Agent'a yÃ¶nlendiriliyor.")
                agent_response_data = await execute_task_agent("FALLBACK_AGENT", prompt_format_values)
            else:
                if DEBUG_MODE: print(f"DEFANSÄ°F (kimlik sonrasÄ±, BEKLENMEDÄ°K DURUM): Niyet '{detected_intent}' iÃ§in hiÃ§bir iÅŸleyici bulunamadÄ±, Fallback Agent'a yÃ¶nlendiriliyor.")
                agent_response_data = await execute_task_agent("FALLBACK_AGENT", prompt_format_values)
        else:
            if DEBUG_MODE: print(f"DEFANSÄ°F (kimlik Ã¶ncesi): Niyet '{detected_intent}' kimlik iÅŸlemleriyle ilgili deÄŸil ({current_orchestrator_state}), Fallback Agent'a yÃ¶nlendiriliyor.")
            agent_response_data = await execute_task_agent("FALLBACK_AGENT", prompt_format_values)

        # ==============================================================================
        # AGENT RESPONSE PROCESSING & STATE UPDATE
        # ==============================================================================
        if agent_response_data and "error" not in agent_response_data:
            ai_message_text = agent_response_data.get("kullanici_yaniti_metni")
            next_turn_orchestrator_state_suggestion = agent_response_data.get("sonraki_python_durumu_onerisi", current_orchestrator_state)
            ai_last_question_type = agent_response_data.get("ai_sordu_soru_tipi", "SORU_YOK")

            # *** YENÄ°: _intent_for_next_turn ayarÄ±nÄ± OFFER_RESPONSE_HANDLER veya ORCHESTRATOR_IMPLICIT_REJECTION_HANDLER'dan gelen verilere gÃ¶re yap ***
            executed_agent_for_direct_action = agent_response_data.get('agent_name_key_executed')
            if executed_agent_for_direct_action in ["OFFER_RESPONSE_HANDLER_AGENT", "ORCHESTRATOR_IMPLICIT_REJECTION_HANDLER"] and ai_message_text is None:
                if agent_response_data.get("kullanicinin_yeni_sordugu_modeller") and \
                   next_turn_orchestrator_state_suggestion == "ARAC_ISLEME_DIREKT_SORGULA":
                    _intent_for_next_turn = "ARAC_SORGU_YENI"
                    _entities_for_next_turn = {"modeller": [m.lower().strip() for m in agent_response_data["kullanicinin_yeni_sordugu_modeller"]], "markalar": [], "tipler": [], "isim_soyisim": None, "onay_durumu": None}
                    _user_input_for_next_turn_context = user_input_text
                    if DEBUG_MODE: print(f"    Sonraki tur iÃ§in ayarlandÄ± (YENÄ° SORGULAMA): _intent='{_intent_for_next_turn}'")
                elif next_turn_orchestrator_state_suggestion == "GENEL_ONERI_ISTEGI_DIREKT_SUN":
                    _intent_for_next_turn = "GENEL_ONERI_ISTEGI"
                    _entities_for_next_turn = {"modeller": [], "markalar": [], "tipler": [], "isim_soyisim": None, "onay_durumu": None}
                    _user_input_for_next_turn_context = user_input_text
                    if DEBUG_MODE: print(f"    Sonraki tur iÃ§in ayarlandÄ± (GENEL Ã–NERÄ°): _intent='{_intent_for_next_turn}'")
            # *** YENÄ° SONU ***

            offered_this_turn_raw = agent_response_data.get("onerilen_modeller_yanitta") or agent_response_data.get("onerilen_veya_teyit_edilen_modeller_yanitta")
            if offered_this_turn_raw and isinstance(offered_this_turn_raw, list):
                session_last_offered_models = [str(m).lower().strip() for m in offered_this_turn_raw if str(m).strip()]
                if DEBUG_MODE: print(f"â„¹ï¸ Sonraki tur iÃ§in konuÅŸulan/Ã¶nerilen modeller gÃ¼ncellendi: {session_last_offered_models}")
            elif ai_last_question_type not in ["ARAC_ILGI_SORUSU", "BAYI_ONAY_SORUSU", "ALTERNATIF_SUNMA_ONAY_SORUSU", "ARAC_TIP_SORUSU", "BAYI_MODEL_TEYIT_SORUSU"]:
                if session_last_offered_models:
                    if DEBUG_MODE: print(f"â„¹ï¸ Belirli bir model teklifi/konuÅŸmasÄ± yapÄ±lmadÄ±ÄŸÄ± iÃ§in session_last_offered_models temizlendi. Soru Tipi: {ai_last_question_type}")
                    session_last_offered_models = []
            rejected_in_turn_raw = agent_response_data.get("reddedilen_modeller_bu_tur", [])
            if rejected_in_turn_raw and isinstance(rejected_in_turn_raw, list):
                newly_rejected_processed = []
                for item_rej in rejected_in_turn_raw:
                    models_from_item = [m.strip().lower() for m in str(item_rej).split(',') if m.strip()]
                    newly_rejected_processed.extend(models_from_item)
                for m_lower in newly_rejected_processed:
                    if m_lower and m_lower not in session_rejected_models:
                        session_rejected_models.append(m_lower)
                        if DEBUG_MODE: print(f"ðŸš« Model reddedilenlere eklendi (Agent: {agent_response_data.get('agent_name_key_executed')}): {m_lower}")

            current_orchestrator_state = next_turn_orchestrator_state_suggestion

            if ai_message_text is None and _intent_for_next_turn and \
               current_orchestrator_state in ["ARAC_ISLEME_DIREKT_SORGULA", "GENEL_ONERI_ISTEGI_DIREKT_SUN"]:
                if ai_last_question_type == "SORU_YOK" and current_orchestrator_state != "GORUSMEYI_BITIR":
                    if DEBUG_MODE: print(f"    AI mesajÄ± boÅŸ & SORU_YOK & sonraki niyet var. Durum '{current_orchestrator_state}'. Direkt devam ediliyor.")
                    continue
            if ai_last_question_type in ["BAYI_ONAY_SORUSU", "ARAC_ILGI_SORUSU", "ALTERNATIF_SUNMA_ONAY_SORUSU", "BAYI_MODEL_TEYIT_SORUSU"]:
                current_orchestrator_state = "TEKLIF_YANITI_BEKLENIYOR"
            elif ai_last_question_type in ["KIMLIK_TEYIT_SORUSU", "KIMLIK_ISIM_SORUSU"]:
                current_orchestrator_state = "KIMLIK_DOGRULAMA_BASLANGIC"
            elif current_orchestrator_state not in ["ARAC_ISLEME_DIREKT_SORGULA", "GENEL_ONERI_ISTEGI_DIREKT_SUN", "GORUSMEYI_BITIR", "TEKLIF_YANITI_BEKLENIYOR", "KIMLIK_DOGRULAMA_BASLANGIC"]:
                 if current_user_details.get("isim_teyit_edildi"): current_orchestrator_state = "ARAC_ISLEME"
                 else: current_orchestrator_state = "KIMLIK_DOGRULAMA_BASLANGIC"
        elif agent_response_data and "error" in agent_response_data:
            ai_message_text = f"ÃœzgÃ¼nÃ¼m, bir sorunla karÅŸÄ±laÅŸtÄ±k ({agent_response_data.get('error', 'bilinmeyen hata')}). LÃ¼tfen farklÄ± bir ÅŸekilde ifade eder misiniz?"
            ai_last_question_type = "GENEL_YARDIM_SORUSU"
            if DEBUG_MODE: print(f"âŒ Agent ({agent_response_data.get('agent_name_key_executed')}) HatasÄ±: {agent_response_data.get('error')}")
            if current_user_details.get("isim_teyit_edildi"): current_orchestrator_state = "ARAC_ISLEME"
            else: current_orchestrator_state = "KIMLIK_DOGRULAMA_BASLANGIC"
        else:
             ai_message_text = "Sistemde bir sorun oluÅŸtu, Ã¶zÃ¼r dileriz. LÃ¼tfen daha sonra tekrar deneyin."
             if DEBUG_MODE: print(f"âŒ Agent_response_data alÄ±namadÄ± veya beklenmedik bir hata oluÅŸtu.")
             current_orchestrator_state = "GORUSMEYI_BITIR"

        if ai_message_text is not None:
            print(f"{datetime.now().strftime('%H:%M:%S')} ðŸ§  AI: {ai_message_text}")
            konusma_gecmisi_log_tamami += f"\nAI: {ai_message_text}"
            gecmis_mesajlar_list_llm_icin.append({"role": "assistant", "content": ai_message_text})
        elif current_orchestrator_state not in ["ARAC_ISLEME_DIREKT_SORGULA", "GENEL_ONERI_ISTEGI_DIREKT_SUN", "GORUSMEYI_BITIR"] and DEBUG_MODE :
            print(f"âš ï¸ AI MesajÄ± BoÅŸ Geldi (None) ancak direkt devam durumu deÄŸil. Durum: {current_orchestrator_state}, Son Soru: {ai_last_question_type}")

        if current_orchestrator_state == "GORUSMEYI_BITIR":
            if DEBUG_MODE: print(f"ðŸ OrkestratÃ¶r durumu GORUSMEYI_BITIR. DÃ¶ngÃ¼ sonlandÄ±rÄ±lÄ±yor.")
            break
        if len(gecmis_mesajlar_list_llm_icin) > 20:
            if DEBUG_MODE: print("KonuÅŸma geÃ§miÅŸi son 10 turu iÃ§erecek ÅŸekilde kÄ±saltÄ±lÄ±yor.")
            gecmis_mesajlar_list_llm_icin = gecmis_mesajlar_list_llm_icin[-20:]

    print("\nðŸ GÃ¶rÃ¼ÅŸme dÃ¶ngÃ¼sÃ¼ tamamlandÄ±. Son analiz ve kayÄ±t iÅŸlemleri yapÄ±lÄ±yor...")
    await analiz_et_ve_kaydet_veritabani_async(
        konusma_gecmisi_str=konusma_gecmisi_log_tamami,
        user_id=original_user_profile["id"],
        user_final_details=current_user_details)
    print("Ä°ÅŸlemler tamamlandÄ±.")

if __name__ == "__main__":
    if not OPENROUTER_API_KEY:
        print("HATA: OPENROUTER_API_KEY .env dosyasÄ±nda bulunamadÄ± veya yÃ¼klenemedi. Program Ã§alÄ±ÅŸtÄ±rÄ±lamÄ±yor.")
    else:
        try:
            asyncio.run(main_async_llm_driven())
        except KeyboardInterrupt:
            print("\nProgram kullanÄ±cÄ± tarafÄ±ndan sonlandÄ±rÄ±ldÄ± (KeyboardInterrupt).")
        except EOFError:
            print("\nVeri giriÅŸi beklenmedik bir ÅŸekilde sonlandÄ± (EOFError).")
        finally:
            print("Asenkron program sonlandÄ±.")